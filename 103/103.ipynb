{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 103 - Underfit, overfit ve validation set\n",
    "\n",
    "Bu kez ağımızın karmaşıklığını arttırmanın ve azaltmanın ağın performansı üzerindeki etkilerini inceleyek ve doğrulama kümesi'nin (*validation set*) niçin gerekli olduğunu ögreneceğiz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training ve test kümelerinin oluşturulması\n",
    "\n",
    "Training ve test kümelerini üreten fonksiyonlarımızda çok fazla değişiklik yok. Geçen derste eklediğimiz bias ve scale değerlerini kaldırdım.\n",
    "\n",
    "testModel fonksiyonunu ise ideal sinus fonksiyonu yerine training verisini çizecek şekilde güncelledim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sine_function(noiserate=0):\n",
    "    def _sine_function(angle):\n",
    "        return (math.sin(angle)+random.uniform(-noiserate,noiserate))\n",
    "    return _sine_function\n",
    "\n",
    "def trainingData(func):\n",
    "    noiserate = 0.2\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(0,100):\n",
    "        angle=random.uniform(-math.pi,math.pi)\n",
    "        X.append(angle)\n",
    "        y.append(func(angle))\n",
    "    return X,y\n",
    "\n",
    "def testData(func):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(-1800,1800):\n",
    "        angle = math.radians(i/10)\n",
    "        X.append(angle)\n",
    "        y.append(func(angle))\n",
    "    return X,y\n",
    "\n",
    "def testModel(Xtrain,ytrain,X,y):\n",
    "    res = model.predict(X, batch_size=32)\n",
    "\n",
    "    plt.scatter(Xtrain,ytrain,s=0.5,label='Training',color='blue')\n",
    "    plt.plot(X,res, label='sonuc',color='red')\n",
    "    plt.xlabel('x (Radyan)')\n",
    "    plt.ylabel('sin(x)')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set \n",
    "\n",
    "Şu anda tek boyutlu girişimiz ve tek boyutlu çıkışımız olduğundan rahatlıkla grafik çizerek ağımızın ne kadar genelleştirme yaptığını doğrulayabiliyoruz. Ancak bir çok *machine learning* problemi çok yüksek sayıda boyuta sahiptir ve o kadar da kolay görselleştirilemez. Bu yüzden *training set*'in bir kısmını ayırıp eğitim için hiç kullanmayız. Böylece ağın hiç görmediği örnekler için de iyi çalışıp çalışmadığını sayısal olarak ölçebileceğimiz bir aracımız olur.\n",
    "\n",
    "## Deney 1 - Underfit\n",
    "\n",
    "Modelin veriyi modellemeye yetecek kadar parametresi olmaması *underfit* denilen olaya, yani bir çeşit aşırı genelleştirmeye yol açar. Bunu test etmek için gizli katmanımızdaki nöron sayısını 1'e indirelim.\n",
    "\n",
    "```python \n",
    "model.fit(X, y, epochs=5000,validation_split=0.1)\n",
    "```\n",
    "Buradaki validation_split=0.1 parametresiyle de training set'in 10'da birinin validation set olarak ayrılacağını söylüyoruz. Her epoch'tan sonra keras bize normal loss'un dışında artık validation loss'u da bildirecek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90 samples, validate on 10 samples\n",
      "Epoch 1/1000\n",
      "90/90 [==============================] - 0s - loss: 8.9406 - val_loss: 2.9118\n",
      "Epoch 2/1000\n",
      "90/90 [==============================] - 0s - loss: 2.9006 - val_loss: 1.3733\n",
      "Epoch 3/1000\n",
      "90/90 [==============================] - 0s - loss: 1.4940 - val_loss: 0.8587\n",
      "Epoch 4/1000\n",
      "90/90 [==============================] - 0s - loss: 0.9532 - val_loss: 0.6527\n",
      "Epoch 5/1000\n",
      "90/90 [==============================] - 0s - loss: 0.6989 - val_loss: 0.5542\n",
      "Epoch 6/1000\n",
      "90/90 [==============================] - 0s - loss: 0.5636 - val_loss: 0.5043\n",
      "Epoch 7/1000\n",
      "90/90 [==============================] - 0s - loss: 0.4718 - val_loss: 0.4816\n",
      "Epoch 8/1000\n",
      "90/90 [==============================] - 0s - loss: 0.4240 - val_loss: 0.4717\n",
      "Epoch 9/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3914 - val_loss: 0.4689\n",
      "Epoch 10/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3700 - val_loss: 0.4695\n",
      "Epoch 11/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3524 - val_loss: 0.4716\n",
      "Epoch 12/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3447 - val_loss: 0.4747\n",
      "Epoch 13/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3368 - val_loss: 0.4771\n",
      "Epoch 14/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3313 - val_loss: 0.4798\n",
      "Epoch 15/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3301 - val_loss: 0.4825\n",
      "Epoch 16/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3242 - val_loss: 0.4846\n",
      "Epoch 17/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3218 - val_loss: 0.4862\n",
      "Epoch 18/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3199 - val_loss: 0.4877\n",
      "Epoch 19/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3186 - val_loss: 0.4889\n",
      "Epoch 20/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3174 - val_loss: 0.4896\n",
      "Epoch 21/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3162 - val_loss: 0.4898\n",
      "Epoch 22/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3148 - val_loss: 0.4903\n",
      "Epoch 23/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3134 - val_loss: 0.4902\n",
      "Epoch 24/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3128 - val_loss: 0.4902\n",
      "Epoch 25/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3115 - val_loss: 0.4897\n",
      "Epoch 26/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3109 - val_loss: 0.4898\n",
      "Epoch 27/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3101 - val_loss: 0.4886\n",
      "Epoch 28/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3093 - val_loss: 0.4880\n",
      "Epoch 29/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3083 - val_loss: 0.4869\n",
      "Epoch 30/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3074 - val_loss: 0.4865\n",
      "Epoch 31/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3065 - val_loss: 0.4858\n",
      "Epoch 32/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3060 - val_loss: 0.4848\n",
      "Epoch 33/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3057 - val_loss: 0.4834\n",
      "Epoch 34/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3049 - val_loss: 0.4825\n",
      "Epoch 35/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3034 - val_loss: 0.4818\n",
      "Epoch 36/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3037 - val_loss: 0.4810\n",
      "Epoch 37/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3019 - val_loss: 0.4803\n",
      "Epoch 38/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3016 - val_loss: 0.4793\n",
      "Epoch 39/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3005 - val_loss: 0.4786\n",
      "Epoch 40/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3002 - val_loss: 0.4776\n",
      "Epoch 41/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2993 - val_loss: 0.4763\n",
      "Epoch 42/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2982 - val_loss: 0.4757\n",
      "Epoch 43/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2974 - val_loss: 0.4749\n",
      "Epoch 44/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2971 - val_loss: 0.4742\n",
      "Epoch 45/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2965 - val_loss: 0.4727\n",
      "Epoch 46/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2960 - val_loss: 0.4714\n",
      "Epoch 47/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.260 - 0s - loss: 0.2940 - val_loss: 0.4701\n",
      "Epoch 48/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2932 - val_loss: 0.4691\n",
      "Epoch 49/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2923 - val_loss: 0.4673\n",
      "Epoch 50/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2916 - val_loss: 0.4665\n",
      "Epoch 51/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2904 - val_loss: 0.4651\n",
      "Epoch 52/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2900 - val_loss: 0.4633\n",
      "Epoch 53/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2896 - val_loss: 0.4622\n",
      "Epoch 54/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2878 - val_loss: 0.4616\n",
      "Epoch 55/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2876 - val_loss: 0.4602\n",
      "Epoch 56/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2865 - val_loss: 0.4582\n",
      "Epoch 57/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2870 - val_loss: 0.4558\n",
      "Epoch 58/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2848 - val_loss: 0.4543\n",
      "Epoch 59/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2839 - val_loss: 0.4543\n",
      "Epoch 60/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2826 - val_loss: 0.4533\n",
      "Epoch 61/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2817 - val_loss: 0.4522\n",
      "Epoch 62/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2815 - val_loss: 0.4521\n",
      "Epoch 63/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2815 - val_loss: 0.4514\n",
      "Epoch 64/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2793 - val_loss: 0.4504\n",
      "Epoch 65/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2785 - val_loss: 0.4493\n",
      "Epoch 66/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2789 - val_loss: 0.4494\n",
      "Epoch 67/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2775 - val_loss: 0.4491\n",
      "Epoch 68/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2769 - val_loss: 0.4472\n",
      "Epoch 69/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2763 - val_loss: 0.4454\n",
      "Epoch 70/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2750 - val_loss: 0.4449\n",
      "Epoch 71/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2756 - val_loss: 0.4436\n",
      "Epoch 72/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2735 - val_loss: 0.4431\n",
      "Epoch 73/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.174 - 0s - loss: 0.2734 - val_loss: 0.4424\n",
      "Epoch 74/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2721 - val_loss: 0.4419\n",
      "Epoch 75/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2712 - val_loss: 0.4409\n",
      "Epoch 76/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2708 - val_loss: 0.4393\n",
      "Epoch 77/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2708 - val_loss: 0.4381\n",
      "Epoch 78/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2697 - val_loss: 0.4364\n",
      "Epoch 79/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2686 - val_loss: 0.4352\n",
      "Epoch 80/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2680 - val_loss: 0.4340\n",
      "Epoch 81/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2676 - val_loss: 0.4331\n",
      "Epoch 82/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2667 - val_loss: 0.4321\n",
      "Epoch 83/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2660 - val_loss: 0.4309\n",
      "Epoch 84/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2656 - val_loss: 0.4308\n",
      "Epoch 85/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2649 - val_loss: 0.4300\n",
      "Epoch 86/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2639 - val_loss: 0.4292\n",
      "Epoch 87/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2642 - val_loss: 0.4275\n",
      "Epoch 88/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2629 - val_loss: 0.4264\n",
      "Epoch 89/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 0.2631 - val_loss: 0.4266\n",
      "Epoch 90/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2614 - val_loss: 0.4256\n",
      "Epoch 91/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2608 - val_loss: 0.4245\n",
      "Epoch 92/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2604 - val_loss: 0.4242\n",
      "Epoch 93/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2595 - val_loss: 0.4236\n",
      "Epoch 94/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2590 - val_loss: 0.4231\n",
      "Epoch 95/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2582 - val_loss: 0.4217\n",
      "Epoch 96/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2578 - val_loss: 0.4200\n",
      "Epoch 97/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2574 - val_loss: 0.4185\n",
      "Epoch 98/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2562 - val_loss: 0.4181\n",
      "Epoch 99/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2558 - val_loss: 0.4176\n",
      "Epoch 100/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2552 - val_loss: 0.4161\n",
      "Epoch 101/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2549 - val_loss: 0.4153\n",
      "Epoch 102/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2545 - val_loss: 0.4135\n",
      "Epoch 103/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2531 - val_loss: 0.4124\n",
      "Epoch 104/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2527 - val_loss: 0.4114\n",
      "Epoch 105/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2528 - val_loss: 0.4113\n",
      "Epoch 106/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2516 - val_loss: 0.4104\n",
      "Epoch 107/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2506 - val_loss: 0.4096\n",
      "Epoch 108/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2506 - val_loss: 0.4088\n",
      "Epoch 109/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2498 - val_loss: 0.4086\n",
      "Epoch 110/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2489 - val_loss: 0.4075\n",
      "Epoch 111/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2481 - val_loss: 0.4063\n",
      "Epoch 112/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2474 - val_loss: 0.4055\n",
      "Epoch 113/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2470 - val_loss: 0.4049\n",
      "Epoch 114/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2462 - val_loss: 0.4041\n",
      "Epoch 115/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2455 - val_loss: 0.4035\n",
      "Epoch 116/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2450 - val_loss: 0.4028\n",
      "Epoch 117/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2450 - val_loss: 0.4014\n",
      "Epoch 118/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2440 - val_loss: 0.4008\n",
      "Epoch 119/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2433 - val_loss: 0.3999\n",
      "Epoch 120/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2433 - val_loss: 0.3981\n",
      "Epoch 121/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2416 - val_loss: 0.3971\n",
      "Epoch 122/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2412 - val_loss: 0.3967\n",
      "Epoch 123/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2403 - val_loss: 0.3956\n",
      "Epoch 124/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2395 - val_loss: 0.3946\n",
      "Epoch 125/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2388 - val_loss: 0.3939\n",
      "Epoch 126/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2393 - val_loss: 0.3928\n",
      "Epoch 127/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.191 - 0s - loss: 0.2375 - val_loss: 0.3919\n",
      "Epoch 128/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2374 - val_loss: 0.3917\n",
      "Epoch 129/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2363 - val_loss: 0.3913\n",
      "Epoch 130/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2354 - val_loss: 0.3904\n",
      "Epoch 131/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2350 - val_loss: 0.3893\n",
      "Epoch 132/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2341 - val_loss: 0.3884\n",
      "Epoch 133/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2337 - val_loss: 0.3880\n",
      "Epoch 134/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2338 - val_loss: 0.3867\n",
      "Epoch 135/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2323 - val_loss: 0.3858\n",
      "Epoch 136/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2319 - val_loss: 0.3845\n",
      "Epoch 137/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2310 - val_loss: 0.3835\n",
      "Epoch 138/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2308 - val_loss: 0.3834\n",
      "Epoch 139/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2302 - val_loss: 0.3828\n",
      "Epoch 140/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2297 - val_loss: 0.3814\n",
      "Epoch 141/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2289 - val_loss: 0.3812\n",
      "Epoch 142/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2281 - val_loss: 0.3803\n",
      "Epoch 143/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2278 - val_loss: 0.3801\n",
      "Epoch 144/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2270 - val_loss: 0.3792\n",
      "Epoch 145/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2265 - val_loss: 0.3783\n",
      "Epoch 146/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2258 - val_loss: 0.3776\n",
      "Epoch 147/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2258 - val_loss: 0.3776\n",
      "Epoch 148/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2248 - val_loss: 0.3767\n",
      "Epoch 149/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2246 - val_loss: 0.3753\n",
      "Epoch 150/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2234 - val_loss: 0.3745\n",
      "Epoch 151/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2229 - val_loss: 0.3733\n",
      "Epoch 152/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2227 - val_loss: 0.3722\n",
      "Epoch 153/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2223 - val_loss: 0.3719\n",
      "Epoch 154/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2212 - val_loss: 0.3714\n",
      "Epoch 155/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2206 - val_loss: 0.3706\n",
      "Epoch 156/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2201 - val_loss: 0.3690\n",
      "Epoch 157/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2199 - val_loss: 0.3685\n",
      "Epoch 158/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2189 - val_loss: 0.3677\n",
      "Epoch 159/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2186 - val_loss: 0.3669\n",
      "Epoch 160/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2183 - val_loss: 0.3658\n",
      "Epoch 161/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2176 - val_loss: 0.3651\n",
      "Epoch 162/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2170 - val_loss: 0.3635\n",
      "Epoch 163/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2161 - val_loss: 0.3626\n",
      "Epoch 164/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2156 - val_loss: 0.3614\n",
      "Epoch 165/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2148 - val_loss: 0.3606\n",
      "Epoch 166/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2144 - val_loss: 0.3602\n",
      "Epoch 167/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2139 - val_loss: 0.3597\n",
      "Epoch 168/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2135 - val_loss: 0.3585\n",
      "Epoch 169/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2129 - val_loss: 0.3581\n",
      "Epoch 170/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2124 - val_loss: 0.3570\n",
      "Epoch 171/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2117 - val_loss: 0.3561\n",
      "Epoch 172/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2118 - val_loss: 0.3545\n",
      "Epoch 173/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2112 - val_loss: 0.3532\n",
      "Epoch 174/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2102 - val_loss: 0.3524\n",
      "Epoch 175/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2098 - val_loss: 0.3519\n",
      "Epoch 176/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2105 - val_loss: 0.3526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2088 - val_loss: 0.3518\n",
      "Epoch 178/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2092 - val_loss: 0.3509\n",
      "Epoch 179/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2082 - val_loss: 0.3501\n",
      "Epoch 180/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2075 - val_loss: 0.3497\n",
      "Epoch 181/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2070 - val_loss: 0.3486\n",
      "Epoch 182/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2068 - val_loss: 0.3474\n",
      "Epoch 183/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2060 - val_loss: 0.3467\n",
      "Epoch 184/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2057 - val_loss: 0.3466\n",
      "Epoch 185/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2059 - val_loss: 0.3453\n",
      "Epoch 186/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2052 - val_loss: 0.3441\n",
      "Epoch 187/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2044 - val_loss: 0.3433\n",
      "Epoch 188/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2045 - val_loss: 0.3422\n",
      "Epoch 189/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2034 - val_loss: 0.3420\n",
      "Epoch 190/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2032 - val_loss: 0.3410\n",
      "Epoch 191/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2025 - val_loss: 0.3406\n",
      "Epoch 192/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2030 - val_loss: 0.3412\n",
      "Epoch 193/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2020 - val_loss: 0.3409\n",
      "Epoch 194/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2023 - val_loss: 0.3391\n",
      "Epoch 195/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2009 - val_loss: 0.3386\n",
      "Epoch 196/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2008 - val_loss: 0.3385\n",
      "Epoch 197/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2002 - val_loss: 0.3375\n",
      "Epoch 198/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2002 - val_loss: 0.3375\n",
      "Epoch 199/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1996 - val_loss: 0.3366\n",
      "Epoch 200/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1993 - val_loss: 0.3361\n",
      "Epoch 201/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1995 - val_loss: 0.3363\n",
      "Epoch 202/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1984 - val_loss: 0.3357\n",
      "Epoch 203/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1980 - val_loss: 0.3349\n",
      "Epoch 204/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1981 - val_loss: 0.3334\n",
      "Epoch 205/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1985 - val_loss: 0.3317\n",
      "Epoch 206/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1972 - val_loss: 0.3314\n",
      "Epoch 207/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1971 - val_loss: 0.3312\n",
      "Epoch 208/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1974 - val_loss: 0.3315\n",
      "Epoch 209/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1964 - val_loss: 0.3310\n",
      "Epoch 210/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1961 - val_loss: 0.3300\n",
      "Epoch 211/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1962 - val_loss: 0.3298\n",
      "Epoch 212/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1958 - val_loss: 0.3285\n",
      "Epoch 213/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1956 - val_loss: 0.3286\n",
      "Epoch 214/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1952 - val_loss: 0.3285\n",
      "Epoch 215/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1945 - val_loss: 0.3274\n",
      "Epoch 216/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1943 - val_loss: 0.3267\n",
      "Epoch 217/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1947 - val_loss: 0.3258\n",
      "Epoch 218/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1940 - val_loss: 0.3254\n",
      "Epoch 219/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1940 - val_loss: 0.3249\n",
      "Epoch 220/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1934 - val_loss: 0.3240\n",
      "Epoch 221/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1935 - val_loss: 0.3239\n",
      "Epoch 222/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1939 - val_loss: 0.3245\n",
      "Epoch 223/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1926 - val_loss: 0.3231\n",
      "Epoch 224/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1924 - val_loss: 0.3222\n",
      "Epoch 225/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1919 - val_loss: 0.3216\n",
      "Epoch 226/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1918 - val_loss: 0.3214\n",
      "Epoch 227/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1920 - val_loss: 0.3207\n",
      "Epoch 228/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1912 - val_loss: 0.3202\n",
      "Epoch 229/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1909 - val_loss: 0.3195\n",
      "Epoch 230/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1909 - val_loss: 0.3188\n",
      "Epoch 231/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1909 - val_loss: 0.3181\n",
      "Epoch 232/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1904 - val_loss: 0.3170\n",
      "Epoch 233/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1903 - val_loss: 0.3162\n",
      "Epoch 234/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1898 - val_loss: 0.3157\n",
      "Epoch 235/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1897 - val_loss: 0.3155\n",
      "Epoch 236/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1893 - val_loss: 0.3151\n",
      "Epoch 237/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1891 - val_loss: 0.3144\n",
      "Epoch 238/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1893 - val_loss: 0.3140\n",
      "Epoch 239/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1892 - val_loss: 0.3125\n",
      "Epoch 240/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1887 - val_loss: 0.3124\n",
      "Epoch 241/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1885 - val_loss: 0.3126\n",
      "Epoch 242/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1881 - val_loss: 0.3125\n",
      "Epoch 243/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1879 - val_loss: 0.3115\n",
      "Epoch 244/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.163 - 0s - loss: 0.1880 - val_loss: 0.3118\n",
      "Epoch 245/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1880 - val_loss: 0.3108\n",
      "Epoch 246/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1890 - val_loss: 0.3097\n",
      "Epoch 247/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1871 - val_loss: 0.3094\n",
      "Epoch 248/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1870 - val_loss: 0.3092\n",
      "Epoch 249/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1870 - val_loss: 0.3085\n",
      "Epoch 250/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1867 - val_loss: 0.3081\n",
      "Epoch 251/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.200 - 0s - loss: 0.1865 - val_loss: 0.3079\n",
      "Epoch 252/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1865 - val_loss: 0.3079\n",
      "Epoch 253/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1869 - val_loss: 0.3083\n",
      "Epoch 254/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1860 - val_loss: 0.3074\n",
      "Epoch 255/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1860 - val_loss: 0.3069\n",
      "Epoch 256/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1860 - val_loss: 0.3063\n",
      "Epoch 257/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1857 - val_loss: 0.3059\n",
      "Epoch 258/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1856 - val_loss: 0.3057\n",
      "Epoch 259/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1859 - val_loss: 0.3061\n",
      "Epoch 260/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1869 - val_loss: 0.3056\n",
      "Epoch 261/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1855 - val_loss: 0.3055\n",
      "Epoch 262/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1850 - val_loss: 0.3048\n",
      "Epoch 263/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1849 - val_loss: 0.3044\n",
      "Epoch 264/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 0.1861 - val_loss: 0.3025\n",
      "Epoch 265/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1852 - val_loss: 0.3014\n",
      "Epoch 266/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1854 - val_loss: 0.3015\n",
      "Epoch 267/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1847 - val_loss: 0.3013\n",
      "Epoch 268/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1844 - val_loss: 0.3006\n",
      "Epoch 269/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.193 - 0s - loss: 0.1843 - val_loss: 0.3002\n",
      "Epoch 270/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1842 - val_loss: 0.3000\n",
      "Epoch 271/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1844 - val_loss: 0.2999\n",
      "Epoch 272/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1843 - val_loss: 0.2990\n",
      "Epoch 273/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1845 - val_loss: 0.2995\n",
      "Epoch 274/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1840 - val_loss: 0.2990\n",
      "Epoch 275/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1841 - val_loss: 0.2987\n",
      "Epoch 276/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1842 - val_loss: 0.2978\n",
      "Epoch 277/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1839 - val_loss: 0.2975\n",
      "Epoch 278/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1840 - val_loss: 0.2975\n",
      "Epoch 279/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1845 - val_loss: 0.2978\n",
      "Epoch 280/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1851 - val_loss: 0.2969\n",
      "Epoch 281/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1842 - val_loss: 0.2970\n",
      "Epoch 282/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1838 - val_loss: 0.2964\n",
      "Epoch 283/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1839 - val_loss: 0.2959\n",
      "Epoch 284/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1835 - val_loss: 0.2958\n",
      "Epoch 285/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1841 - val_loss: 0.2949\n",
      "Epoch 286/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1838 - val_loss: 0.2944\n",
      "Epoch 287/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1844 - val_loss: 0.2939\n",
      "Epoch 288/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1840 - val_loss: 0.2946\n",
      "Epoch 289/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1844 - val_loss: 0.2935\n",
      "Epoch 290/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1839 - val_loss: 0.2944\n",
      "Epoch 291/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1838 - val_loss: 0.2950\n",
      "Epoch 292/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1838 - val_loss: 0.2941\n",
      "Epoch 293/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1838 - val_loss: 0.2945\n",
      "Epoch 294/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1833 - val_loss: 0.2946\n",
      "Epoch 295/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1834 - val_loss: 0.2947\n",
      "Epoch 296/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1832 - val_loss: 0.2942\n",
      "Epoch 297/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1836 - val_loss: 0.2942\n",
      "Epoch 298/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1831 - val_loss: 0.2939\n",
      "Epoch 299/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1834 - val_loss: 0.2944\n",
      "Epoch 300/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1834 - val_loss: 0.2936\n",
      "Epoch 301/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1835 - val_loss: 0.2943\n",
      "Epoch 302/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1837 - val_loss: 0.2929\n",
      "Epoch 303/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1842 - val_loss: 0.2923\n",
      "Epoch 304/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.214 - 0s - loss: 0.1839 - val_loss: 0.2931\n",
      "Epoch 305/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1832 - val_loss: 0.2930\n",
      "Epoch 306/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1829 - val_loss: 0.2927\n",
      "Epoch 307/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1831 - val_loss: 0.2925\n",
      "Epoch 308/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1831 - val_loss: 0.2920\n",
      "Epoch 309/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1832 - val_loss: 0.2918\n",
      "Epoch 310/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1830 - val_loss: 0.2923\n",
      "Epoch 311/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1830 - val_loss: 0.2922\n",
      "Epoch 312/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1828 - val_loss: 0.2921\n",
      "Epoch 313/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1829 - val_loss: 0.2922\n",
      "Epoch 314/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1832 - val_loss: 0.2912\n",
      "Epoch 315/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1841 - val_loss: 0.2922\n",
      "Epoch 316/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1831 - val_loss: 0.2928\n",
      "Epoch 317/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1838 - val_loss: 0.2925\n",
      "Epoch 318/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2919\n",
      "Epoch 319/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1832 - val_loss: 0.2912\n",
      "Epoch 320/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1828 - val_loss: 0.2914\n",
      "Epoch 321/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1835 - val_loss: 0.2910\n",
      "Epoch 322/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1830 - val_loss: 0.2911\n",
      "Epoch 323/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1829 - val_loss: 0.2904\n",
      "Epoch 324/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2900\n",
      "Epoch 325/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1832 - val_loss: 0.2891\n",
      "Epoch 326/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1832 - val_loss: 0.2893\n",
      "Epoch 327/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1828 - val_loss: 0.2898\n",
      "Epoch 328/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2900\n",
      "Epoch 329/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2900\n",
      "Epoch 330/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1832 - val_loss: 0.2904\n",
      "Epoch 331/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2900\n",
      "Epoch 332/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2896\n",
      "Epoch 333/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1828 - val_loss: 0.2893\n",
      "Epoch 334/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1829 - val_loss: 0.2899\n",
      "Epoch 335/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2895\n",
      "Epoch 336/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1833 - val_loss: 0.2907\n",
      "Epoch 337/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2912\n",
      "Epoch 338/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2911\n",
      "Epoch 339/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1837 - val_loss: 0.2918\n",
      "Epoch 340/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1832 - val_loss: 0.2925\n",
      "Epoch 341/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2918\n",
      "Epoch 342/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1840 - val_loss: 0.2928\n",
      "Epoch 343/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2920\n",
      "Epoch 344/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2908\n",
      "Epoch 345/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2904\n",
      "Epoch 346/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2893\n",
      "Epoch 347/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2898\n",
      "Epoch 348/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2896\n",
      "Epoch 349/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2889\n",
      "Epoch 350/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1828 - val_loss: 0.2879\n",
      "Epoch 351/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2886\n",
      "Epoch 352/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1830 - val_loss: 0.2893\n",
      "Epoch 353/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2884\n",
      "Epoch 354/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1831 - val_loss: 0.2873\n",
      "Epoch 355/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2872\n",
      "Epoch 356/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2880\n",
      "Epoch 357/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2884\n",
      "Epoch 358/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2885\n",
      "Epoch 359/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2887\n",
      "Epoch 360/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2891\n",
      "Epoch 361/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2880\n",
      "Epoch 362/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2884\n",
      "Epoch 363/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2876\n",
      "Epoch 364/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2877\n",
      "Epoch 365/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2880\n",
      "Epoch 366/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2882\n",
      "Epoch 367/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2882\n",
      "Epoch 368/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1830 - val_loss: 0.2893\n",
      "Epoch 369/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2885\n",
      "Epoch 370/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2880\n",
      "Epoch 371/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1831 - val_loss: 0.2871\n",
      "Epoch 372/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1833 - val_loss: 0.2885\n",
      "Epoch 373/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2885\n",
      "Epoch 374/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2882\n",
      "Epoch 375/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1830 - val_loss: 0.2885\n",
      "Epoch 376/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2880\n",
      "Epoch 377/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2871\n",
      "Epoch 378/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2870\n",
      "Epoch 379/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2876\n",
      "Epoch 380/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2873\n",
      "Epoch 381/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2873\n",
      "Epoch 382/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2872\n",
      "Epoch 383/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1829 - val_loss: 0.2861\n",
      "Epoch 384/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2869\n",
      "Epoch 385/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2867\n",
      "Epoch 386/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2875\n",
      "Epoch 387/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1830 - val_loss: 0.2872\n",
      "Epoch 388/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2869\n",
      "Epoch 389/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2867\n",
      "Epoch 390/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1835 - val_loss: 0.2884\n",
      "Epoch 391/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2877\n",
      "Epoch 392/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2873\n",
      "Epoch 393/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2865\n",
      "Epoch 394/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2861\n",
      "Epoch 395/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2859\n",
      "Epoch 396/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2864\n",
      "Epoch 397/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2858\n",
      "Epoch 398/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2856\n",
      "Epoch 399/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2855\n",
      "Epoch 400/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2859\n",
      "Epoch 401/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2858\n",
      "Epoch 402/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2857\n",
      "Epoch 403/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2860\n",
      "Epoch 404/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1829 - val_loss: 0.2854\n",
      "Epoch 405/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2858\n",
      "Epoch 406/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2855\n",
      "Epoch 407/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1830 - val_loss: 0.2856\n",
      "Epoch 408/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2858\n",
      "Epoch 409/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1829 - val_loss: 0.2862\n",
      "Epoch 410/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2868\n",
      "Epoch 411/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2872\n",
      "Epoch 412/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1830 - val_loss: 0.2868\n",
      "Epoch 413/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2867\n",
      "Epoch 414/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2863\n",
      "Epoch 415/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1829 - val_loss: 0.2854\n",
      "Epoch 416/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2850\n",
      "Epoch 417/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1829 - val_loss: 0.2859\n",
      "Epoch 418/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2860\n",
      "Epoch 419/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2859\n",
      "Epoch 420/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2868\n",
      "Epoch 421/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2871\n",
      "Epoch 422/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2870\n",
      "Epoch 423/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2872\n",
      "Epoch 424/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2874\n",
      "Epoch 425/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1828 - val_loss: 0.2870\n",
      "Epoch 426/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2868\n",
      "Epoch 427/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2875\n",
      "Epoch 428/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1831 - val_loss: 0.2872\n",
      "Epoch 429/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2872\n",
      "Epoch 430/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2870\n",
      "Epoch 431/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2877\n",
      "Epoch 432/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2874\n",
      "Epoch 433/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2874\n",
      "Epoch 434/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2879\n",
      "Epoch 435/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2876\n",
      "Epoch 436/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2878\n",
      "Epoch 437/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2872\n",
      "Epoch 438/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2868\n",
      "Epoch 439/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2872\n",
      "Epoch 440/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2872\n",
      "Epoch 441/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2864\n",
      "Epoch 442/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2860\n",
      "Epoch 443/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2860\n",
      "Epoch 444/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2867\n",
      "Epoch 445/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1828 - val_loss: 0.2860\n",
      "Epoch 446/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1833 - val_loss: 0.2849\n",
      "Epoch 447/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2851\n",
      "Epoch 448/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2853\n",
      "Epoch 449/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2859\n",
      "Epoch 450/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2856\n",
      "Epoch 451/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2860\n",
      "Epoch 452/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2859\n",
      "Epoch 453/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2866\n",
      "Epoch 454/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1834 - val_loss: 0.2867\n",
      "Epoch 455/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2870\n",
      "Epoch 456/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2872\n",
      "Epoch 457/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2873\n",
      "Epoch 458/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1829 - val_loss: 0.2862\n",
      "Epoch 459/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1834 - val_loss: 0.2855\n",
      "Epoch 460/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2855\n",
      "Epoch 461/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2857\n",
      "Epoch 462/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1828 - val_loss: 0.2851\n",
      "Epoch 463/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2849\n",
      "Epoch 464/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1829 - val_loss: 0.2854\n",
      "Epoch 465/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2848\n",
      "Epoch 466/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2855\n",
      "Epoch 467/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2860\n",
      "Epoch 468/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2862\n",
      "Epoch 469/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2862\n",
      "Epoch 470/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2871\n",
      "Epoch 471/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2870\n",
      "Epoch 472/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2864\n",
      "Epoch 473/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2861\n",
      "Epoch 474/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2863\n",
      "Epoch 475/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2869\n",
      "Epoch 476/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2871\n",
      "Epoch 477/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2865\n",
      "Epoch 478/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2867\n",
      "Epoch 479/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2865\n",
      "Epoch 480/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2860\n",
      "Epoch 481/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2863\n",
      "Epoch 482/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2862\n",
      "Epoch 483/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2860\n",
      "Epoch 484/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2861\n",
      "Epoch 485/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2862\n",
      "Epoch 486/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2857\n",
      "Epoch 487/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2862\n",
      "Epoch 488/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2858\n",
      "Epoch 489/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2852\n",
      "Epoch 490/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1833 - val_loss: 0.2844\n",
      "Epoch 491/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2841\n",
      "Epoch 492/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2843\n",
      "Epoch 493/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2843\n",
      "Epoch 494/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2842\n",
      "Epoch 495/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2840\n",
      "Epoch 496/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2839\n",
      "Epoch 497/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2844\n",
      "Epoch 498/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2846\n",
      "Epoch 499/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2845\n",
      "Epoch 500/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2851\n",
      "Epoch 501/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2841\n",
      "Epoch 502/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.212 - 0s - loss: 0.1822 - val_loss: 0.2843\n",
      "Epoch 503/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2839\n",
      "Epoch 504/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2844\n",
      "Epoch 505/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2842\n",
      "Epoch 506/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2836\n",
      "Epoch 507/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1834 - val_loss: 0.2840\n",
      "Epoch 508/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2844\n",
      "Epoch 509/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2844\n",
      "Epoch 510/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2840\n",
      "Epoch 511/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1834 - val_loss: 0.2852\n",
      "Epoch 512/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2853\n",
      "Epoch 513/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2844\n",
      "Epoch 514/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2846\n",
      "Epoch 515/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2848\n",
      "Epoch 516/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2851\n",
      "Epoch 517/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2860\n",
      "Epoch 518/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2857\n",
      "Epoch 519/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2852\n",
      "Epoch 520/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2851\n",
      "Epoch 521/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2846\n",
      "Epoch 522/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.176 - 0s - loss: 0.1828 - val_loss: 0.2857\n",
      "Epoch 523/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2861\n",
      "Epoch 524/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1837 - val_loss: 0.2851\n",
      "Epoch 525/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2852\n",
      "Epoch 526/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2847\n",
      "Epoch 527/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2839\n",
      "Epoch 528/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2840\n",
      "Epoch 529/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1829 - val_loss: 0.2838\n",
      "Epoch 530/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2841\n",
      "Epoch 531/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2838\n",
      "Epoch 532/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2840\n",
      "Epoch 533/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2843\n",
      "Epoch 534/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1829 - val_loss: 0.2852\n",
      "Epoch 535/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2850\n",
      "Epoch 536/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2848\n",
      "Epoch 537/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2852\n",
      "Epoch 538/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2853\n",
      "Epoch 539/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.215 - 0s - loss: 0.1822 - val_loss: 0.2849\n",
      "Epoch 540/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2852\n",
      "Epoch 541/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2857\n",
      "Epoch 542/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2854\n",
      "Epoch 543/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2849\n",
      "Epoch 544/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2848\n",
      "Epoch 545/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2848\n",
      "Epoch 546/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2851\n",
      "Epoch 547/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1834 - val_loss: 0.2845\n",
      "Epoch 548/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2839\n",
      "Epoch 549/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2846\n",
      "Epoch 550/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1830 - val_loss: 0.2844\n",
      "Epoch 551/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1828 - val_loss: 0.2836\n",
      "Epoch 552/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2835\n",
      "Epoch 553/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2840\n",
      "Epoch 554/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2847\n",
      "Epoch 555/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1836 - val_loss: 0.2847\n",
      "Epoch 556/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2845\n",
      "Epoch 557/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2844\n",
      "Epoch 558/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2843\n",
      "Epoch 559/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2848\n",
      "Epoch 560/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2842\n",
      "Epoch 561/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2848\n",
      "Epoch 562/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1838 - val_loss: 0.2853\n",
      "Epoch 563/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2853\n",
      "Epoch 564/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1831 - val_loss: 0.2843\n",
      "Epoch 565/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1833 - val_loss: 0.2833\n",
      "Epoch 566/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2837\n",
      "Epoch 567/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2843\n",
      "Epoch 568/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1832 - val_loss: 0.2838\n",
      "Epoch 569/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2839\n",
      "Epoch 570/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2844\n",
      "Epoch 571/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2842\n",
      "Epoch 572/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2849\n",
      "Epoch 573/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2853\n",
      "Epoch 574/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2846\n",
      "Epoch 575/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1828 - val_loss: 0.2843\n",
      "Epoch 576/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2844\n",
      "Epoch 577/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2845\n",
      "Epoch 578/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1832 - val_loss: 0.2836\n",
      "Epoch 579/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.132 - 0s - loss: 0.1828 - val_loss: 0.2842\n",
      "Epoch 580/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2838\n",
      "Epoch 581/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1828 - val_loss: 0.2831\n",
      "Epoch 582/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1838 - val_loss: 0.2823\n",
      "Epoch 583/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1831 - val_loss: 0.2830\n",
      "Epoch 584/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2830\n",
      "Epoch 585/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2834\n",
      "Epoch 586/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1830 - val_loss: 0.2838\n",
      "Epoch 587/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2843\n",
      "Epoch 588/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1831 - val_loss: 0.2839\n",
      "Epoch 589/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2837\n",
      "Epoch 590/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2831\n",
      "Epoch 591/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2829\n",
      "Epoch 592/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2837\n",
      "Epoch 593/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2842\n",
      "Epoch 594/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2836\n",
      "Epoch 595/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2847\n",
      "Epoch 596/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2849\n",
      "Epoch 597/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2843\n",
      "Epoch 598/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2844\n",
      "Epoch 599/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2842\n",
      "Epoch 600/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1832 - val_loss: 0.2837\n",
      "Epoch 601/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2836\n",
      "Epoch 602/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2839\n",
      "Epoch 603/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2838\n",
      "Epoch 604/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1828 - val_loss: 0.2842\n",
      "Epoch 605/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2844\n",
      "Epoch 606/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1829 - val_loss: 0.2857\n",
      "Epoch 607/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2854\n",
      "Epoch 608/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2853\n",
      "Epoch 609/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2853\n",
      "Epoch 610/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2849\n",
      "Epoch 611/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1830 - val_loss: 0.2844\n",
      "Epoch 612/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2841\n",
      "Epoch 613/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2844\n",
      "Epoch 614/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1831 - val_loss: 0.2850\n",
      "Epoch 615/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1829 - val_loss: 0.2858\n",
      "Epoch 616/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2860\n",
      "Epoch 617/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2856\n",
      "Epoch 618/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2847\n",
      "Epoch 619/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1829 - val_loss: 0.2859\n",
      "Epoch 620/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2861\n",
      "Epoch 621/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2863\n",
      "Epoch 622/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2859\n",
      "Epoch 623/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1828 - val_loss: 0.2850\n",
      "Epoch 624/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1834 - val_loss: 0.2838\n",
      "Epoch 625/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2844\n",
      "Epoch 626/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2836\n",
      "Epoch 627/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2838\n",
      "Epoch 628/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2840\n",
      "Epoch 629/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2848\n",
      "Epoch 630/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2852\n",
      "Epoch 631/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1830 - val_loss: 0.2864\n",
      "Epoch 632/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2861\n",
      "Epoch 633/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2861\n",
      "Epoch 634/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2857\n",
      "Epoch 635/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1833 - val_loss: 0.2848\n",
      "Epoch 636/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2848\n",
      "Epoch 637/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2850\n",
      "Epoch 638/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2846\n",
      "Epoch 639/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2853\n",
      "Epoch 640/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1828 - val_loss: 0.2842\n",
      "Epoch 641/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2845\n",
      "Epoch 642/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2839\n",
      "Epoch 643/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2835\n",
      "Epoch 644/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1831 - val_loss: 0.2842\n",
      "Epoch 645/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2841\n",
      "Epoch 646/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2847\n",
      "Epoch 647/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2850\n",
      "Epoch 648/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2854\n",
      "Epoch 649/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1829 - val_loss: 0.2857\n",
      "Epoch 650/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2859\n",
      "Epoch 651/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2859\n",
      "Epoch 652/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2863\n",
      "Epoch 653/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.174 - 0s - loss: 0.1825 - val_loss: 0.2853\n",
      "Epoch 654/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2854\n",
      "Epoch 655/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2857\n",
      "Epoch 656/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.181 - 0s - loss: 0.1823 - val_loss: 0.2856\n",
      "Epoch 657/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2853\n",
      "Epoch 658/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2845\n",
      "Epoch 659/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2837\n",
      "Epoch 660/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2840\n",
      "Epoch 661/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2836\n",
      "Epoch 662/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2849\n",
      "Epoch 663/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2852\n",
      "Epoch 664/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2854\n",
      "Epoch 665/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2847\n",
      "Epoch 666/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2844\n",
      "Epoch 667/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2851\n",
      "Epoch 668/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2850\n",
      "Epoch 669/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2852\n",
      "Epoch 670/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2847\n",
      "Epoch 671/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2844\n",
      "Epoch 672/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2843\n",
      "Epoch 673/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2847\n",
      "Epoch 674/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2847\n",
      "Epoch 675/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1831 - val_loss: 0.2844\n",
      "Epoch 676/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2851\n",
      "Epoch 677/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2847\n",
      "Epoch 678/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1829 - val_loss: 0.2839\n",
      "Epoch 679/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.167 - 0s - loss: 0.1826 - val_loss: 0.2847\n",
      "Epoch 680/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1829 - val_loss: 0.2859\n",
      "Epoch 681/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2865\n",
      "Epoch 682/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2866\n",
      "Epoch 683/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2867\n",
      "Epoch 684/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1829 - val_loss: 0.2867\n",
      "Epoch 685/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2865\n",
      "Epoch 686/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2868\n",
      "Epoch 687/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2864\n",
      "Epoch 688/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2864\n",
      "Epoch 689/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2856\n",
      "Epoch 690/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2857\n",
      "Epoch 691/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2860\n",
      "Epoch 692/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2865\n",
      "Epoch 693/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2868\n",
      "Epoch 694/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2866\n",
      "Epoch 695/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2853\n",
      "Epoch 696/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2859\n",
      "Epoch 697/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2859\n",
      "Epoch 698/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2856\n",
      "Epoch 699/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2858\n",
      "Epoch 700/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2853\n",
      "Epoch 701/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1828 - val_loss: 0.2858\n",
      "Epoch 702/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2863\n",
      "Epoch 703/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1838 - val_loss: 0.2859\n",
      "Epoch 704/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2856\n",
      "Epoch 705/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2848\n",
      "Epoch 706/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2843\n",
      "Epoch 707/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2844\n",
      "Epoch 708/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1828 - val_loss: 0.2856\n",
      "Epoch 709/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2848\n",
      "Epoch 710/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2846\n",
      "Epoch 711/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2849\n",
      "Epoch 712/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2849\n",
      "Epoch 713/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2842\n",
      "Epoch 714/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2846\n",
      "Epoch 715/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2841\n",
      "Epoch 716/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2836\n",
      "Epoch 717/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2837\n",
      "Epoch 718/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2842\n",
      "Epoch 719/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2849\n",
      "Epoch 720/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2850\n",
      "Epoch 721/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2851\n",
      "Epoch 722/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2846\n",
      "Epoch 723/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2842\n",
      "Epoch 724/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2842\n",
      "Epoch 725/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.170 - 0s - loss: 0.1823 - val_loss: 0.2841\n",
      "Epoch 726/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2848\n",
      "Epoch 727/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1839 - val_loss: 0.2846\n",
      "Epoch 728/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2846\n",
      "Epoch 729/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2848\n",
      "Epoch 730/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2850\n",
      "Epoch 731/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2853\n",
      "Epoch 732/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2846\n",
      "Epoch 733/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2853\n",
      "Epoch 734/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2854\n",
      "Epoch 735/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2847\n",
      "Epoch 736/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2847\n",
      "Epoch 737/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2842\n",
      "Epoch 738/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1828 - val_loss: 0.2845\n",
      "Epoch 739/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2847\n",
      "Epoch 740/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1829 - val_loss: 0.2845\n",
      "Epoch 741/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2837\n",
      "Epoch 742/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.212 - 0s - loss: 0.1821 - val_loss: 0.2839\n",
      "Epoch 743/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2847\n",
      "Epoch 744/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2851\n",
      "Epoch 745/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2849\n",
      "Epoch 746/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2857\n",
      "Epoch 747/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2848\n",
      "Epoch 748/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2847\n",
      "Epoch 749/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2853\n",
      "Epoch 750/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.192 - 0s - loss: 0.1821 - val_loss: 0.2850\n",
      "Epoch 751/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2849\n",
      "Epoch 752/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.150 - 0s - loss: 0.1822 - val_loss: 0.2852\n",
      "Epoch 753/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1829 - val_loss: 0.2857\n",
      "Epoch 754/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2864\n",
      "Epoch 755/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2864\n",
      "Epoch 756/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1831 - val_loss: 0.2849\n",
      "Epoch 757/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.206 - 0s - loss: 0.1826 - val_loss: 0.2852\n",
      "Epoch 758/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2847\n",
      "Epoch 759/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2842\n",
      "Epoch 760/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2842\n",
      "Epoch 761/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2847\n",
      "Epoch 762/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2851\n",
      "Epoch 763/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1828 - val_loss: 0.2857\n",
      "Epoch 764/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2850\n",
      "Epoch 765/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2846\n",
      "Epoch 766/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.245 - 0s - loss: 0.1824 - val_loss: 0.2849\n",
      "Epoch 767/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2848\n",
      "Epoch 768/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.173 - 0s - loss: 0.1828 - val_loss: 0.2853\n",
      "Epoch 769/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2856\n",
      "Epoch 770/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2856\n",
      "Epoch 771/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2851\n",
      "Epoch 772/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2850\n",
      "Epoch 773/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2855\n",
      "Epoch 774/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2854\n",
      "Epoch 775/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1831 - val_loss: 0.2840\n",
      "Epoch 776/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2842\n",
      "Epoch 777/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2839\n",
      "Epoch 778/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2851\n",
      "Epoch 779/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1834 - val_loss: 0.2865\n",
      "Epoch 780/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1833 - val_loss: 0.2875\n",
      "Epoch 781/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2870\n",
      "Epoch 782/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2871\n",
      "Epoch 783/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1830 - val_loss: 0.2854\n",
      "Epoch 784/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2858\n",
      "Epoch 785/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2846\n",
      "Epoch 786/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2839\n",
      "Epoch 787/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2841\n",
      "Epoch 788/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2841\n",
      "Epoch 789/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2843\n",
      "Epoch 790/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2844\n",
      "Epoch 791/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2854\n",
      "Epoch 792/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2848\n",
      "Epoch 793/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2858\n",
      "Epoch 794/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2857\n",
      "Epoch 795/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2855\n",
      "Epoch 796/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2845\n",
      "Epoch 797/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1832 - val_loss: 0.2850\n",
      "Epoch 798/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1831 - val_loss: 0.2837\n",
      "Epoch 799/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1828 - val_loss: 0.2832\n",
      "Epoch 800/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2827\n",
      "Epoch 801/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2828\n",
      "Epoch 802/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2827\n",
      "Epoch 803/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1829 - val_loss: 0.2827\n",
      "Epoch 804/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2831\n",
      "Epoch 805/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1831 - val_loss: 0.2823\n",
      "Epoch 806/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2825\n",
      "Epoch 807/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2823\n",
      "Epoch 808/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.215 - 0s - loss: 0.1825 - val_loss: 0.2830\n",
      "Epoch 809/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2824\n",
      "Epoch 810/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2833\n",
      "Epoch 811/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2839\n",
      "Epoch 812/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1834 - val_loss: 0.2853\n",
      "Epoch 813/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2851\n",
      "Epoch 814/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2854\n",
      "Epoch 815/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2849\n",
      "Epoch 816/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2841\n",
      "Epoch 817/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2849\n",
      "Epoch 818/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1832 - val_loss: 0.2836\n",
      "Epoch 819/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2841\n",
      "Epoch 820/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2840\n",
      "Epoch 821/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2846\n",
      "Epoch 822/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2844\n",
      "Epoch 823/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2843\n",
      "Epoch 824/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2843\n",
      "Epoch 825/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2840\n",
      "Epoch 826/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2843\n",
      "Epoch 827/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2839\n",
      "Epoch 828/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2842\n",
      "Epoch 829/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2840\n",
      "Epoch 830/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1830 - val_loss: 0.2843\n",
      "Epoch 831/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2848\n",
      "Epoch 832/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1833 - val_loss: 0.2837\n",
      "Epoch 833/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1828 - val_loss: 0.2843\n",
      "Epoch 834/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1835 - val_loss: 0.2861\n",
      "Epoch 835/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2859\n",
      "Epoch 836/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2864\n",
      "Epoch 837/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2856\n",
      "Epoch 838/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2852\n",
      "Epoch 839/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1832 - val_loss: 0.2849\n",
      "Epoch 840/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2851\n",
      "Epoch 841/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1833 - val_loss: 0.2863\n",
      "Epoch 842/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2861\n",
      "Epoch 843/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2867\n",
      "Epoch 844/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2857\n",
      "Epoch 845/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2850\n",
      "Epoch 846/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2849\n",
      "Epoch 847/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2854\n",
      "Epoch 848/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2854\n",
      "Epoch 849/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2850\n",
      "Epoch 850/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2855\n",
      "Epoch 851/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.203 - 0s - loss: 0.1822 - val_loss: 0.2858\n",
      "Epoch 852/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2858\n",
      "Epoch 853/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2852\n",
      "Epoch 854/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2854\n",
      "Epoch 855/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2852\n",
      "Epoch 856/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2846\n",
      "Epoch 857/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2842\n",
      "Epoch 858/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2847\n",
      "Epoch 859/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1828 - val_loss: 0.2854\n",
      "Epoch 860/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2858\n",
      "Epoch 861/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1840 - val_loss: 0.2875\n",
      "Epoch 862/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1831 - val_loss: 0.2863\n",
      "Epoch 863/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1836 - val_loss: 0.2872\n",
      "Epoch 864/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2868\n",
      "Epoch 865/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2865\n",
      "Epoch 866/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1828 - val_loss: 0.2871\n",
      "Epoch 867/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2877\n",
      "Epoch 868/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2879\n",
      "Epoch 869/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1838 - val_loss: 0.2893\n",
      "Epoch 870/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2888\n",
      "Epoch 871/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2877\n",
      "Epoch 872/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2875\n",
      "Epoch 873/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2870\n",
      "Epoch 874/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2860\n",
      "Epoch 875/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1830 - val_loss: 0.2866\n",
      "Epoch 876/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2862\n",
      "Epoch 877/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2857\n",
      "Epoch 878/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2863\n",
      "Epoch 879/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2855\n",
      "Epoch 880/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2850\n",
      "Epoch 881/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2857\n",
      "Epoch 882/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2847\n",
      "Epoch 883/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2853\n",
      "Epoch 884/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2855\n",
      "Epoch 885/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2860\n",
      "Epoch 886/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2855\n",
      "Epoch 887/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2849\n",
      "Epoch 888/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2845\n",
      "Epoch 889/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2841\n",
      "Epoch 890/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2844\n",
      "Epoch 891/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1832 - val_loss: 0.2859\n",
      "Epoch 892/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1828 - val_loss: 0.2862\n",
      "Epoch 893/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1832 - val_loss: 0.2854\n",
      "Epoch 894/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2851\n",
      "Epoch 895/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2850\n",
      "Epoch 896/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1833 - val_loss: 0.2837\n",
      "Epoch 897/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2842\n",
      "Epoch 898/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2839\n",
      "Epoch 899/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1833 - val_loss: 0.2852\n",
      "Epoch 900/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2855\n",
      "Epoch 901/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2852\n",
      "Epoch 902/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2847\n",
      "Epoch 903/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1830 - val_loss: 0.2852\n",
      "Epoch 904/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2846\n",
      "Epoch 905/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2852\n",
      "Epoch 906/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2857\n",
      "Epoch 907/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1828 - val_loss: 0.2853\n",
      "Epoch 908/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2854\n",
      "Epoch 909/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1830 - val_loss: 0.2850\n",
      "Epoch 910/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2843\n",
      "Epoch 911/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2840\n",
      "Epoch 912/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2841\n",
      "Epoch 913/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2843\n",
      "Epoch 914/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2842\n",
      "Epoch 915/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2838\n",
      "Epoch 916/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1830 - val_loss: 0.2851\n",
      "Epoch 917/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2850\n",
      "Epoch 918/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2857\n",
      "Epoch 919/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1834 - val_loss: 0.2870\n",
      "Epoch 920/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1829 - val_loss: 0.2878\n",
      "Epoch 921/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2878\n",
      "Epoch 922/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2882\n",
      "Epoch 923/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1831 - val_loss: 0.2866\n",
      "Epoch 924/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2861\n",
      "Epoch 925/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2866\n",
      "Epoch 926/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2862\n",
      "Epoch 927/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2855\n",
      "Epoch 928/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2851\n",
      "Epoch 929/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2852\n",
      "Epoch 930/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1832 - val_loss: 0.2856\n",
      "Epoch 931/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2849\n",
      "Epoch 932/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2847\n",
      "Epoch 933/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2857\n",
      "Epoch 934/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1830 - val_loss: 0.2852\n",
      "Epoch 935/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1832 - val_loss: 0.2867\n",
      "Epoch 936/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2857\n",
      "Epoch 937/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2853\n",
      "Epoch 938/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2852\n",
      "Epoch 939/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1841 - val_loss: 0.2862\n",
      "Epoch 940/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1838 - val_loss: 0.2852\n",
      "Epoch 941/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2850\n",
      "Epoch 942/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2850\n",
      "Epoch 943/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2849\n",
      "Epoch 944/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1829 - val_loss: 0.2861\n",
      "Epoch 945/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2851\n",
      "Epoch 946/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1835 - val_loss: 0.2850\n",
      "Epoch 947/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2851\n",
      "Epoch 948/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2847\n",
      "Epoch 949/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2844\n",
      "Epoch 950/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2851\n",
      "Epoch 951/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2849\n",
      "Epoch 952/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1828 - val_loss: 0.2844\n",
      "Epoch 953/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2847\n",
      "Epoch 954/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2854\n",
      "Epoch 955/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2849\n",
      "Epoch 956/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1828 - val_loss: 0.2841\n",
      "Epoch 957/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2842\n",
      "Epoch 958/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2840\n",
      "Epoch 959/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2852\n",
      "Epoch 960/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2862\n",
      "Epoch 961/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2851\n",
      "Epoch 962/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2855\n",
      "Epoch 963/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2844\n",
      "Epoch 964/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2847\n",
      "Epoch 965/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2848\n",
      "Epoch 966/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1829 - val_loss: 0.2845\n",
      "Epoch 967/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2850\n",
      "Epoch 968/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2851\n",
      "Epoch 969/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2852\n",
      "Epoch 970/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2852\n",
      "Epoch 971/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2851\n",
      "Epoch 972/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2850\n",
      "Epoch 973/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2842\n",
      "Epoch 974/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2840\n",
      "Epoch 975/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2839\n",
      "Epoch 976/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2831\n",
      "Epoch 977/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2832\n",
      "Epoch 978/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2845\n",
      "Epoch 979/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1824 - val_loss: 0.2840\n",
      "Epoch 980/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1831 - val_loss: 0.2841\n",
      "Epoch 981/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2834\n",
      "Epoch 982/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1828 - val_loss: 0.2833\n",
      "Epoch 983/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2840\n",
      "Epoch 984/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2834\n",
      "Epoch 985/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2830\n",
      "Epoch 986/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2836\n",
      "Epoch 987/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2835\n",
      "Epoch 988/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2844\n",
      "Epoch 989/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1837 - val_loss: 0.2862\n",
      "Epoch 990/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.111 - 0s - loss: 0.1829 - val_loss: 0.2859\n",
      "Epoch 991/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2858\n",
      "Epoch 992/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1821 - val_loss: 0.2856\n",
      "Epoch 993/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1827 - val_loss: 0.2860\n",
      "Epoch 994/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1829 - val_loss: 0.2856\n",
      "Epoch 995/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1825 - val_loss: 0.2855\n",
      "Epoch 996/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2857\n",
      "Epoch 997/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2863\n",
      "Epoch 998/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2861\n",
      "Epoch 999/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1826 - val_loss: 0.2858\n",
      "Epoch 1000/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1822 - val_loss: 0.2852\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEKCAYAAADuEgmxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0ea2384fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1, input_shape=(1,), activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='sgd')\n",
    "sine = sine_function(noiserate=0.3)\n",
    "X,y = trainingData(sine)\n",
    "X_test, y_test = testData(sine)\n",
    "model.fit(X, y, epochs=1000,validation_split=0.1)\n",
    "testModel(X,y,X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model bu kadar az parametreyle ancak tek bir dirseği olan iki çizgi modelleyebildiğinden veriye bu kadar yaklaşabildi. \n",
    "\n",
    "Eğitimin sonunda training loss'un da validation loss'un da oldukça yüksek bir değerde düşmeyi bıraktığını görüyoruz. Bu ağınızın underfit durumunda olduğuna işaret eder. Ağın performansı hem gördüğü, hem de daha önceki görmediği örnekler için kötü durumda.\n",
    "\n",
    "## Deney 2 - Overfit\n",
    "\n",
    "Skalanın tam karşı noktasında ise *overfit* var. Modelimizin karmaşıklığı gerekenden fazlaysa bu kez de model genelleme yapma yetisini kaybeder. Bunu test etmek için elimizde problemle orantısız büyüklükte bir ağ tanımlayalım. Bu ağ 280, 180, 80 ve 80 nörana sahip 4 ayrı gizli katman (*hidden layer*) içeriyor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90 samples, validate on 10 samples\n",
      "Epoch 1/1000\n",
      "90/90 [==============================] - 0s - loss: 0.3531 - val_loss: 0.2585\n",
      "Epoch 2/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2181 - val_loss: 0.1432\n",
      "Epoch 3/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1945 - val_loss: 0.0937\n",
      "Epoch 4/1000\n",
      "90/90 [==============================] - 0s - loss: 0.2074 - val_loss: 0.0931\n",
      "Epoch 5/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1883 - val_loss: 0.1107\n",
      "Epoch 6/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1780 - val_loss: 0.1388\n",
      "Epoch 7/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1750 - val_loss: 0.1385\n",
      "Epoch 8/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1672 - val_loss: 0.1132\n",
      "Epoch 9/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1568 - val_loss: 0.0925\n",
      "Epoch 10/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1516 - val_loss: 0.0820\n",
      "Epoch 11/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1425 - val_loss: 0.0773\n",
      "Epoch 12/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1371 - val_loss: 0.0818\n",
      "Epoch 13/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1284 - val_loss: 0.0709\n",
      "Epoch 14/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1185 - val_loss: 0.0632\n",
      "Epoch 15/1000\n",
      "90/90 [==============================] - 0s - loss: 0.1077 - val_loss: 0.0634\n",
      "Epoch 16/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0993 - val_loss: 0.0536\n",
      "Epoch 17/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0885 - val_loss: 0.0493\n",
      "Epoch 18/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0769 - val_loss: 0.0394\n",
      "Epoch 19/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0690 - val_loss: 0.0397\n",
      "Epoch 20/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0593 - val_loss: 0.0403\n",
      "Epoch 21/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0482 - val_loss: 0.0209\n",
      "Epoch 22/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0372 - val_loss: 0.0386\n",
      "Epoch 23/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0321 - val_loss: 0.0179\n",
      "Epoch 24/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0229 - val_loss: 0.0287\n",
      "Epoch 25/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0191 - val_loss: 0.0153\n",
      "Epoch 26/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0180 - val_loss: 0.0303\n",
      "Epoch 27/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0181 - val_loss: 0.0151\n",
      "Epoch 28/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0184 - val_loss: 0.0288\n",
      "Epoch 29/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0202 - val_loss: 0.0117\n",
      "Epoch 30/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0199 - val_loss: 0.0245\n",
      "Epoch 31/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0179 - val_loss: 0.0299\n",
      "Epoch 32/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0160 - val_loss: 0.0140\n",
      "Epoch 33/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0171 - val_loss: 0.0303\n",
      "Epoch 34/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0175 - val_loss: 0.0276\n",
      "Epoch 35/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0158 - val_loss: 0.0117\n",
      "Epoch 36/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0131 - val_loss: 0.0228\n",
      "Epoch 37/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0138 - val_loss: 0.0245\n",
      "Epoch 38/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0138 - val_loss: 0.0173\n",
      "Epoch 39/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0142 - val_loss: 0.0193\n",
      "Epoch 40/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0125 - val_loss: 0.0217\n",
      "Epoch 41/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0139 - val_loss: 0.0296\n",
      "Epoch 42/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0148 - val_loss: 0.0175\n",
      "Epoch 43/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0158 - val_loss: 0.0168\n",
      "Epoch 44/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0141 - val_loss: 0.0301\n",
      "Epoch 45/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0137 - val_loss: 0.0132\n",
      "Epoch 46/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0135 - val_loss: 0.0204\n",
      "Epoch 47/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0121 - val_loss: 0.0280\n",
      "Epoch 48/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0114 - val_loss: 0.0152\n",
      "Epoch 49/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0144 - val_loss: 0.0192\n",
      "Epoch 50/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0108 - val_loss: 0.0277\n",
      "Epoch 51/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0126 - val_loss: 0.0162\n",
      "Epoch 52/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0114 - val_loss: 0.0231\n",
      "Epoch 53/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0119 - val_loss: 0.0163\n",
      "Epoch 54/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0125 - val_loss: 0.0153\n",
      "Epoch 55/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0135 - val_loss: 0.0272\n",
      "Epoch 56/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0113 - val_loss: 0.0155\n",
      "Epoch 57/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0143 - val_loss: 0.0175\n",
      "Epoch 58/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0161 - val_loss: 0.0238\n",
      "Epoch 59/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0131 - val_loss: 0.0141\n",
      "Epoch 60/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0151 - val_loss: 0.0324\n",
      "Epoch 61/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0187 - val_loss: 0.0249\n",
      "Epoch 62/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0139 - val_loss: 0.0146\n",
      "Epoch 63/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0135 - val_loss: 0.0267\n",
      "Epoch 64/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0128 - val_loss: 0.0190\n",
      "Epoch 65/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0127 - val_loss: 0.0206\n",
      "Epoch 66/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0116 - val_loss: 0.0213\n",
      "Epoch 67/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0110 - val_loss: 0.0162\n",
      "Epoch 68/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0116 - val_loss: 0.0214\n",
      "Epoch 69/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0107 - val_loss: 0.0208\n",
      "Epoch 70/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0107 - val_loss: 0.0158\n",
      "Epoch 71/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0123 - val_loss: 0.0209\n",
      "Epoch 72/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0209\n",
      "Epoch 73/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0120 - val_loss: 0.0130\n",
      "Epoch 74/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0109 - val_loss: 0.0246\n",
      "Epoch 75/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0121 - val_loss: 0.0222\n",
      "Epoch 76/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0108 - val_loss: 0.0165\n",
      "Epoch 77/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0115 - val_loss: 0.0199\n",
      "Epoch 78/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0119 - val_loss: 0.0213\n",
      "Epoch 79/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0118 - val_loss: 0.0166\n",
      "Epoch 80/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0121 - val_loss: 0.0198\n",
      "Epoch 81/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0116 - val_loss: 0.0242\n",
      "Epoch 82/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0116 - val_loss: 0.0150\n",
      "Epoch 83/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0116 - val_loss: 0.0206\n",
      "Epoch 84/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0109 - val_loss: 0.0175\n",
      "Epoch 85/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0232\n",
      "Epoch 86/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0163\n",
      "Epoch 87/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0110 - val_loss: 0.0185\n",
      "Epoch 88/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0105 - val_loss: 0.0214\n",
      "Epoch 89/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 0.0112 - val_loss: 0.0168\n",
      "Epoch 90/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0115 - val_loss: 0.0172\n",
      "Epoch 91/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0122 - val_loss: 0.0240\n",
      "Epoch 92/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0107 - val_loss: 0.0174\n",
      "Epoch 93/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0112 - val_loss: 0.0169\n",
      "Epoch 94/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0112 - val_loss: 0.0192\n",
      "Epoch 95/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0109 - val_loss: 0.0177\n",
      "Epoch 96/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0188\n",
      "Epoch 97/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0217\n",
      "Epoch 98/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0111 - val_loss: 0.0186\n",
      "Epoch 99/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0129 - val_loss: 0.0159\n",
      "Epoch 100/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0124 - val_loss: 0.0242\n",
      "Epoch 101/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0120 - val_loss: 0.0152\n",
      "Epoch 102/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0121 - val_loss: 0.0211\n",
      "Epoch 103/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0118 - val_loss: 0.0218\n",
      "Epoch 104/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0109 - val_loss: 0.0200\n",
      "Epoch 105/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0116 - val_loss: 0.0232\n",
      "Epoch 106/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0114 - val_loss: 0.0182\n",
      "Epoch 107/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0163\n",
      "Epoch 108/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0110 - val_loss: 0.0207\n",
      "Epoch 109/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0109 - val_loss: 0.0189\n",
      "Epoch 110/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0109 - val_loss: 0.0208\n",
      "Epoch 111/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0102 - val_loss: 0.0146\n",
      "Epoch 112/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0114 - val_loss: 0.0209\n",
      "Epoch 113/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0115 - val_loss: 0.0210\n",
      "Epoch 114/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0115 - val_loss: 0.0190\n",
      "Epoch 115/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0110 - val_loss: 0.0221\n",
      "Epoch 116/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0101 - val_loss: 0.0193\n",
      "Epoch 117/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0118 - val_loss: 0.0182\n",
      "Epoch 118/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0121 - val_loss: 0.0245\n",
      "Epoch 119/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0131 - val_loss: 0.0201\n",
      "Epoch 120/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0109 - val_loss: 0.0160\n",
      "Epoch 121/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0116 - val_loss: 0.0254\n",
      "Epoch 122/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0133 - val_loss: 0.0214\n",
      "Epoch 123/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0117 - val_loss: 0.0190\n",
      "Epoch 124/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0113 - val_loss: 0.0189\n",
      "Epoch 125/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0112 - val_loss: 0.0248\n",
      "Epoch 126/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0116 - val_loss: 0.0159\n",
      "Epoch 127/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0129 - val_loss: 0.0171\n",
      "Epoch 128/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0130 - val_loss: 0.0328\n",
      "Epoch 129/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0130 - val_loss: 0.0153\n",
      "Epoch 130/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0115 - val_loss: 0.0193\n",
      "Epoch 131/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0108 - val_loss: 0.0235\n",
      "Epoch 132/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0167\n",
      "Epoch 133/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0172\n",
      "Epoch 134/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0110 - val_loss: 0.0239\n",
      "Epoch 135/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0107 - val_loss: 0.0224\n",
      "Epoch 136/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0138\n",
      "Epoch 137/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0110 - val_loss: 0.0175\n",
      "Epoch 138/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0110 - val_loss: 0.0241\n",
      "Epoch 139/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0107 - val_loss: 0.0133\n",
      "Epoch 140/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0112 - val_loss: 0.0213\n",
      "Epoch 141/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0118 - val_loss: 0.0174\n",
      "Epoch 142/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0108 - val_loss: 0.0168\n",
      "Epoch 143/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0115 - val_loss: 0.0251\n",
      "Epoch 144/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0113 - val_loss: 0.0170\n",
      "Epoch 145/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0109 - val_loss: 0.0159\n",
      "Epoch 146/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0150 - val_loss: 0.0210\n",
      "Epoch 147/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0124 - val_loss: 0.0210\n",
      "Epoch 148/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0137 - val_loss: 0.0238\n",
      "Epoch 149/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0149 - val_loss: 0.0175\n",
      "Epoch 150/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0146 - val_loss: 0.0221\n",
      "Epoch 151/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0151 - val_loss: 0.0281\n",
      "Epoch 152/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0164 - val_loss: 0.0081\n",
      "Epoch 153/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0156 - val_loss: 0.0266\n",
      "Epoch 154/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0130 - val_loss: 0.0275\n",
      "Epoch 155/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0133 - val_loss: 0.0194\n",
      "Epoch 156/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0138 - val_loss: 0.0237\n",
      "Epoch 157/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0125 - val_loss: 0.0196\n",
      "Epoch 158/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0105 - val_loss: 0.0189\n",
      "Epoch 159/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0115 - val_loss: 0.0193\n",
      "Epoch 160/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0107 - val_loss: 0.0244\n",
      "Epoch 161/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0101 - val_loss: 0.0196\n",
      "Epoch 162/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0120 - val_loss: 0.0199\n",
      "Epoch 163/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0108 - val_loss: 0.0197\n",
      "Epoch 164/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0105 - val_loss: 0.0178\n",
      "Epoch 165/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0138 - val_loss: 0.0175\n",
      "Epoch 166/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0158 - val_loss: 0.0260\n",
      "Epoch 167/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0125 - val_loss: 0.0161\n",
      "Epoch 168/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0118 - val_loss: 0.0226\n",
      "Epoch 169/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0116 - val_loss: 0.0172\n",
      "Epoch 170/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0218\n",
      "Epoch 171/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0117 - val_loss: 0.0231\n",
      "Epoch 172/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0113 - val_loss: 0.0166\n",
      "Epoch 173/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0100 - val_loss: 0.0231\n",
      "Epoch 174/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0109 - val_loss: 0.0209\n",
      "Epoch 175/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0108 - val_loss: 0.0186\n",
      "Epoch 176/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0107 - val_loss: 0.0189\n",
      "Epoch 177/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 0.0103 - val_loss: 0.0193\n",
      "Epoch 178/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0107 - val_loss: 0.0188\n",
      "Epoch 179/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0105 - val_loss: 0.0180\n",
      "Epoch 180/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0105 - val_loss: 0.0214\n",
      "Epoch 181/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0181\n",
      "Epoch 182/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0098 - val_loss: 0.0210\n",
      "Epoch 183/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0105 - val_loss: 0.0194\n",
      "Epoch 184/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0099 - val_loss: 0.0216\n",
      "Epoch 185/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0101 - val_loss: 0.0188\n",
      "Epoch 186/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0099 - val_loss: 0.0216\n",
      "Epoch 187/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0100 - val_loss: 0.0200\n",
      "Epoch 188/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0101 - val_loss: 0.0168\n",
      "Epoch 189/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0105 - val_loss: 0.0201\n",
      "Epoch 190/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0114 - val_loss: 0.0221\n",
      "Epoch 191/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0097 - val_loss: 0.0157\n",
      "Epoch 192/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0214\n",
      "Epoch 193/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0112 - val_loss: 0.0196\n",
      "Epoch 194/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0107 - val_loss: 0.0170\n",
      "Epoch 195/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0204\n",
      "Epoch 196/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0250\n",
      "Epoch 197/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0100 - val_loss: 0.0158\n",
      "Epoch 198/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0107 - val_loss: 0.0181\n",
      "Epoch 199/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0101 - val_loss: 0.0231\n",
      "Epoch 200/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0099 - val_loss: 0.0166\n",
      "Epoch 201/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0115 - val_loss: 0.0178\n",
      "Epoch 202/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0100 - val_loss: 0.0240\n",
      "Epoch 203/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0102 - val_loss: 0.0169\n",
      "Epoch 204/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0113 - val_loss: 0.0196\n",
      "Epoch 205/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0105 - val_loss: 0.0205\n",
      "Epoch 206/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0103 - val_loss: 0.0146\n",
      "Epoch 207/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0101 - val_loss: 0.0250\n",
      "Epoch 208/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0111 - val_loss: 0.0208\n",
      "Epoch 209/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0107 - val_loss: 0.0156\n",
      "Epoch 210/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0109 - val_loss: 0.0214\n",
      "Epoch 211/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0111 - val_loss: 0.0189\n",
      "Epoch 212/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0220\n",
      "Epoch 213/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0114 - val_loss: 0.0197\n",
      "Epoch 214/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0102 - val_loss: 0.0207\n",
      "Epoch 215/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0227\n",
      "Epoch 216/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0107 - val_loss: 0.0171\n",
      "Epoch 217/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0103 - val_loss: 0.0193\n",
      "Epoch 218/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0213\n",
      "Epoch 219/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0109 - val_loss: 0.0173\n",
      "Epoch 220/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0102 - val_loss: 0.0221\n",
      "Epoch 221/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0111 - val_loss: 0.0206\n",
      "Epoch 222/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0108 - val_loss: 0.0206\n",
      "Epoch 223/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0130 - val_loss: 0.0172\n",
      "Epoch 224/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0109 - val_loss: 0.0190\n",
      "Epoch 225/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0123 - val_loss: 0.0225\n",
      "Epoch 226/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0108 - val_loss: 0.0292\n",
      "Epoch 227/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0130\n",
      "Epoch 228/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0122 - val_loss: 0.0165\n",
      "Epoch 229/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0116 - val_loss: 0.0267\n",
      "Epoch 230/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0178\n",
      "Epoch 231/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0114 - val_loss: 0.0212\n",
      "Epoch 232/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0103 - val_loss: 0.0200\n",
      "Epoch 233/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0112 - val_loss: 0.0176\n",
      "Epoch 234/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0108 - val_loss: 0.0233\n",
      "Epoch 235/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0103 - val_loss: 0.0199\n",
      "Epoch 236/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0192\n",
      "Epoch 237/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0142 - val_loss: 0.0177\n",
      "Epoch 238/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0107 - val_loss: 0.0181\n",
      "Epoch 239/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0100 - val_loss: 0.0221\n",
      "Epoch 240/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0101 - val_loss: 0.0198\n",
      "Epoch 241/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0113 - val_loss: 0.0202\n",
      "Epoch 242/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0117 - val_loss: 0.0198\n",
      "Epoch 243/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0224\n",
      "Epoch 244/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0117 - val_loss: 0.0185\n",
      "Epoch 245/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0121 - val_loss: 0.0166\n",
      "Epoch 246/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0119 - val_loss: 0.0216\n",
      "Epoch 247/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0116 - val_loss: 0.0190\n",
      "Epoch 248/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0204\n",
      "Epoch 249/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0192\n",
      "Epoch 250/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0108 - val_loss: 0.0197\n",
      "Epoch 251/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0214\n",
      "Epoch 252/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0109 - val_loss: 0.0217\n",
      "Epoch 253/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0108 - val_loss: 0.0187\n",
      "Epoch 254/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0109 - val_loss: 0.0219\n",
      "Epoch 255/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0103 - val_loss: 0.0168\n",
      "Epoch 256/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0112 - val_loss: 0.0238\n",
      "Epoch 257/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0099 - val_loss: 0.0210\n",
      "Epoch 258/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0173\n",
      "Epoch 259/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0174\n",
      "Epoch 260/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0102 - val_loss: 0.0188\n",
      "Epoch 261/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0105 - val_loss: 0.0265\n",
      "Epoch 262/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0109 - val_loss: 0.0177\n",
      "Epoch 263/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0102 - val_loss: 0.0178\n",
      "Epoch 264/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0102 - val_loss: 0.0224\n",
      "Epoch 265/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 0.0116 - val_loss: 0.0198\n",
      "Epoch 266/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0112 - val_loss: 0.0198\n",
      "Epoch 267/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0118 - val_loss: 0.0222\n",
      "Epoch 268/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0119 - val_loss: 0.0162\n",
      "Epoch 269/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0130 - val_loss: 0.0249\n",
      "Epoch 270/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0123 - val_loss: 0.0231\n",
      "Epoch 271/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0107 - val_loss: 0.0134\n",
      "Epoch 272/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0123 - val_loss: 0.0249\n",
      "Epoch 273/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0137 - val_loss: 0.0233\n",
      "Epoch 274/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0109 - val_loss: 0.0166\n",
      "Epoch 275/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0126 - val_loss: 0.0255\n",
      "Epoch 276/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0119 - val_loss: 0.0229\n",
      "Epoch 277/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0122 - val_loss: 0.0128\n",
      "Epoch 278/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0131 - val_loss: 0.0284\n",
      "Epoch 279/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0115 - val_loss: 0.0227\n",
      "Epoch 280/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0109 - val_loss: 0.0193\n",
      "Epoch 281/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0109 - val_loss: 0.0240\n",
      "Epoch 282/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0101 - val_loss: 0.0201\n",
      "Epoch 283/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0181\n",
      "Epoch 284/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0227\n",
      "Epoch 285/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0107 - val_loss: 0.0220\n",
      "Epoch 286/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0112 - val_loss: 0.0152\n",
      "Epoch 287/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0116 - val_loss: 0.0229\n",
      "Epoch 288/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0178\n",
      "Epoch 289/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0100 - val_loss: 0.0218\n",
      "Epoch 290/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0100 - val_loss: 0.0209\n",
      "Epoch 291/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0100 - val_loss: 0.0178\n",
      "Epoch 292/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0115 - val_loss: 0.0181\n",
      "Epoch 293/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0121 - val_loss: 0.0272\n",
      "Epoch 294/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0113 - val_loss: 0.0148\n",
      "Epoch 295/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0133 - val_loss: 0.0223\n",
      "Epoch 296/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0123 - val_loss: 0.0257\n",
      "Epoch 297/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0114 - val_loss: 0.0196\n",
      "Epoch 298/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0129 - val_loss: 0.0263\n",
      "Epoch 299/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0128 - val_loss: 0.0198\n",
      "Epoch 300/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0123 - val_loss: 0.0205\n",
      "Epoch 301/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0110 - val_loss: 0.0229\n",
      "Epoch 302/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.010 - 0s - loss: 0.0123 - val_loss: 0.0192\n",
      "Epoch 303/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0107 - val_loss: 0.0318\n",
      "Epoch 304/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0133 - val_loss: 0.0201\n",
      "Epoch 305/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.010 - 0s - loss: 0.0102 - val_loss: 0.0134\n",
      "Epoch 306/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0110 - val_loss: 0.0259\n",
      "Epoch 307/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.008 - 0s - loss: 0.0109 - val_loss: 0.0239\n",
      "Epoch 308/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0157\n",
      "Epoch 309/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0108 - val_loss: 0.0195\n",
      "Epoch 310/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0122 - val_loss: 0.0263\n",
      "Epoch 311/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0108 - val_loss: 0.0176\n",
      "Epoch 312/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0222\n",
      "Epoch 313/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0115 - val_loss: 0.0192\n",
      "Epoch 314/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0110 - val_loss: 0.0182\n",
      "Epoch 315/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0112 - val_loss: 0.0237\n",
      "Epoch 316/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0193\n",
      "Epoch 317/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0212\n",
      "Epoch 318/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0102 - val_loss: 0.0202\n",
      "Epoch 319/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0111 - val_loss: 0.0206\n",
      "Epoch 320/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0096 - val_loss: 0.0218\n",
      "Epoch 321/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0117 - val_loss: 0.0204\n",
      "Epoch 322/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0102 - val_loss: 0.0176\n",
      "Epoch 323/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0102 - val_loss: 0.0246\n",
      "Epoch 324/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0120 - val_loss: 0.0251\n",
      "Epoch 325/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0096 - val_loss: 0.0151\n",
      "Epoch 326/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0114 - val_loss: 0.0201\n",
      "Epoch 327/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0098 - val_loss: 0.0283\n",
      "Epoch 328/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0119 - val_loss: 0.0197\n",
      "Epoch 329/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0101 - val_loss: 0.0193\n",
      "Epoch 330/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0236\n",
      "Epoch 331/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0205\n",
      "Epoch 332/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0100 - val_loss: 0.0160\n",
      "Epoch 333/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0108 - val_loss: 0.0237\n",
      "Epoch 334/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0101 - val_loss: 0.0205\n",
      "Epoch 335/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.008 - 0s - loss: 0.0099 - val_loss: 0.0208\n",
      "Epoch 336/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0107 - val_loss: 0.0199\n",
      "Epoch 337/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0098 - val_loss: 0.0235\n",
      "Epoch 338/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0101 - val_loss: 0.0206\n",
      "Epoch 339/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0108 - val_loss: 0.0184\n",
      "Epoch 340/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0101 - val_loss: 0.0237\n",
      "Epoch 341/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0103 - val_loss: 0.0221\n",
      "Epoch 342/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0176\n",
      "Epoch 343/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0103 - val_loss: 0.0205\n",
      "Epoch 344/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0096 - val_loss: 0.0223\n",
      "Epoch 345/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0097 - val_loss: 0.0182\n",
      "Epoch 346/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0229\n",
      "Epoch 347/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0105 - val_loss: 0.0199\n",
      "Epoch 348/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0180\n",
      "Epoch 349/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.010 - 0s - loss: 0.0091 - val_loss: 0.0199\n",
      "Epoch 350/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0103 - val_loss: 0.0225\n",
      "Epoch 351/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0188\n",
      "Epoch 352/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0107 - val_loss: 0.0196\n",
      "Epoch 353/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0133 - val_loss: 0.0271\n",
      "Epoch 354/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0173\n",
      "Epoch 355/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0189\n",
      "Epoch 356/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0117 - val_loss: 0.0245\n",
      "Epoch 357/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0113 - val_loss: 0.0176\n",
      "Epoch 358/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0115 - val_loss: 0.0200\n",
      "Epoch 359/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0112 - val_loss: 0.0267\n",
      "Epoch 360/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0098 - val_loss: 0.0214\n",
      "Epoch 361/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0109 - val_loss: 0.0150\n",
      "Epoch 362/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0233\n",
      "Epoch 363/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0110 - val_loss: 0.0229\n",
      "Epoch 364/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0103 - val_loss: 0.0171\n",
      "Epoch 365/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0105 - val_loss: 0.0262\n",
      "Epoch 366/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0196\n",
      "Epoch 367/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0180\n",
      "Epoch 368/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0099 - val_loss: 0.0225\n",
      "Epoch 369/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0117 - val_loss: 0.0213\n",
      "Epoch 370/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0109 - val_loss: 0.0199\n",
      "Epoch 371/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0260\n",
      "Epoch 372/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0103 - val_loss: 0.0157\n",
      "Epoch 373/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0103 - val_loss: 0.0184\n",
      "Epoch 374/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0198\n",
      "Epoch 375/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0101 - val_loss: 0.0217\n",
      "Epoch 376/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0238\n",
      "Epoch 377/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0183\n",
      "Epoch 378/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0206\n",
      "Epoch 379/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0219\n",
      "Epoch 380/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0099 - val_loss: 0.0167\n",
      "Epoch 381/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0110 - val_loss: 0.0193\n",
      "Epoch 382/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0107 - val_loss: 0.0238\n",
      "Epoch 383/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0096 - val_loss: 0.0176\n",
      "Epoch 384/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.009 - 0s - loss: 0.0119 - val_loss: 0.0207\n",
      "Epoch 385/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0205\n",
      "Epoch 386/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0112 - val_loss: 0.0210\n",
      "Epoch 387/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0221\n",
      "Epoch 388/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0112 - val_loss: 0.0170\n",
      "Epoch 389/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.006 - 0s - loss: 0.0113 - val_loss: 0.0205\n",
      "Epoch 390/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0102 - val_loss: 0.0304\n",
      "Epoch 391/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0129 - val_loss: 0.0206\n",
      "Epoch 392/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0112 - val_loss: 0.0180\n",
      "Epoch 393/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0122 - val_loss: 0.0244\n",
      "Epoch 394/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0113 - val_loss: 0.0231\n",
      "Epoch 395/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0098 - val_loss: 0.0175\n",
      "Epoch 396/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0108 - val_loss: 0.0234\n",
      "Epoch 397/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0098 - val_loss: 0.0228\n",
      "Epoch 398/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0102 - val_loss: 0.0180\n",
      "Epoch 399/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.008 - 0s - loss: 0.0095 - val_loss: 0.0240\n",
      "Epoch 400/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0214\n",
      "Epoch 401/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0100 - val_loss: 0.0210\n",
      "Epoch 402/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0101 - val_loss: 0.0199\n",
      "Epoch 403/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0108 - val_loss: 0.0207\n",
      "Epoch 404/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0105 - val_loss: 0.0232\n",
      "Epoch 405/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0113 - val_loss: 0.0201\n",
      "Epoch 406/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0196\n",
      "Epoch 407/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0213\n",
      "Epoch 408/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0199\n",
      "Epoch 409/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0216\n",
      "Epoch 410/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0209\n",
      "Epoch 411/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0197\n",
      "Epoch 412/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0180\n",
      "Epoch 413/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0224\n",
      "Epoch 414/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0098 - val_loss: 0.0189\n",
      "Epoch 415/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0112 - val_loss: 0.0217\n",
      "Epoch 416/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0115 - val_loss: 0.0246\n",
      "Epoch 417/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0151\n",
      "Epoch 418/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0136 - val_loss: 0.0270\n",
      "Epoch 419/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0116 - val_loss: 0.0205\n",
      "Epoch 420/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0142 - val_loss: 0.0155\n",
      "Epoch 421/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.010 - 0s - loss: 0.0103 - val_loss: 0.0322\n",
      "Epoch 422/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0129 - val_loss: 0.0217\n",
      "Epoch 423/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0113 - val_loss: 0.0175\n",
      "Epoch 424/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0120 - val_loss: 0.0268\n",
      "Epoch 425/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0126 - val_loss: 0.0240\n",
      "Epoch 426/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0113 - val_loss: 0.0170\n",
      "Epoch 427/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0105 - val_loss: 0.0216\n",
      "Epoch 428/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0108 - val_loss: 0.0210\n",
      "Epoch 429/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0099 - val_loss: 0.0205\n",
      "Epoch 430/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0203\n",
      "Epoch 431/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0185\n",
      "Epoch 432/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0111 - val_loss: 0.0199\n",
      "Epoch 433/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0114 - val_loss: 0.0241\n",
      "Epoch 434/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0119 - val_loss: 0.0258\n",
      "Epoch 435/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0165\n",
      "Epoch 436/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0218\n",
      "Epoch 437/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0109 - val_loss: 0.0214\n",
      "Epoch 438/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 0.0086 - val_loss: 0.0198\n",
      "Epoch 439/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0101 - val_loss: 0.0167\n",
      "Epoch 440/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0208\n",
      "Epoch 441/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.005 - 0s - loss: 0.0101 - val_loss: 0.0236\n",
      "Epoch 442/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0099 - val_loss: 0.0174\n",
      "Epoch 443/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0096 - val_loss: 0.0220\n",
      "Epoch 444/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0100 - val_loss: 0.0220\n",
      "Epoch 445/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0089 - val_loss: 0.0202\n",
      "Epoch 446/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0102 - val_loss: 0.0228\n",
      "Epoch 447/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0098 - val_loss: 0.0197\n",
      "Epoch 448/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0103 - val_loss: 0.0172\n",
      "Epoch 449/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0102 - val_loss: 0.0251\n",
      "Epoch 450/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0111 - val_loss: 0.0200\n",
      "Epoch 451/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0099 - val_loss: 0.0204\n",
      "Epoch 452/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0195\n",
      "Epoch 453/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0096 - val_loss: 0.0199\n",
      "Epoch 454/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0096 - val_loss: 0.0258\n",
      "Epoch 455/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0182\n",
      "Epoch 456/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0098 - val_loss: 0.0188\n",
      "Epoch 457/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0203\n",
      "Epoch 458/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0193\n",
      "Epoch 459/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0208\n",
      "Epoch 460/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0189\n",
      "Epoch 461/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0089 - val_loss: 0.0218\n",
      "Epoch 462/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0089 - val_loss: 0.0205\n",
      "Epoch 463/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0225\n",
      "Epoch 464/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0097 - val_loss: 0.0249\n",
      "Epoch 465/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0169\n",
      "Epoch 466/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0098 - val_loss: 0.0200\n",
      "Epoch 467/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0242\n",
      "Epoch 468/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0199\n",
      "Epoch 469/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0191\n",
      "Epoch 470/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0204\n",
      "Epoch 471/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0187\n",
      "Epoch 472/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0221\n",
      "Epoch 473/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0096 - val_loss: 0.0200\n",
      "Epoch 474/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0085 - val_loss: 0.0217\n",
      "Epoch 475/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0195\n",
      "Epoch 476/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0178\n",
      "Epoch 477/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0218\n",
      "Epoch 478/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0218\n",
      "Epoch 479/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0107 - val_loss: 0.0188\n",
      "Epoch 480/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0262\n",
      "Epoch 481/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0114 - val_loss: 0.0182\n",
      "Epoch 482/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0109 - val_loss: 0.0202\n",
      "Epoch 483/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0102 - val_loss: 0.0249\n",
      "Epoch 484/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0100 - val_loss: 0.0184\n",
      "Epoch 485/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0124 - val_loss: 0.0218\n",
      "Epoch 486/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0107 - val_loss: 0.0236\n",
      "Epoch 487/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0113 - val_loss: 0.0188\n",
      "Epoch 488/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0110 - val_loss: 0.0239\n",
      "Epoch 489/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0110 - val_loss: 0.0221\n",
      "Epoch 490/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0191\n",
      "Epoch 491/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0101 - val_loss: 0.0229\n",
      "Epoch 492/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0102 - val_loss: 0.0193\n",
      "Epoch 493/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0112 - val_loss: 0.0208\n",
      "Epoch 494/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0102 - val_loss: 0.0259\n",
      "Epoch 495/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0107 - val_loss: 0.0205\n",
      "Epoch 496/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0097 - val_loss: 0.0151\n",
      "Epoch 497/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0110 - val_loss: 0.0221\n",
      "Epoch 498/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.009 - 0s - loss: 0.0113 - val_loss: 0.0219\n",
      "Epoch 499/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0103 - val_loss: 0.0161\n",
      "Epoch 500/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0105 - val_loss: 0.0258\n",
      "Epoch 501/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0117 - val_loss: 0.0193\n",
      "Epoch 502/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.008 - 0s - loss: 0.0100 - val_loss: 0.0201\n",
      "Epoch 503/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0099 - val_loss: 0.0262\n",
      "Epoch 504/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.010 - 0s - loss: 0.0098 - val_loss: 0.0188\n",
      "Epoch 505/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0213\n",
      "Epoch 506/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0225\n",
      "Epoch 507/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0203\n",
      "Epoch 508/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0184\n",
      "Epoch 509/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0098 - val_loss: 0.0215\n",
      "Epoch 510/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0193\n",
      "Epoch 511/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0215\n",
      "Epoch 512/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0244\n",
      "Epoch 513/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0096 - val_loss: 0.0171\n",
      "Epoch 514/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0187\n",
      "Epoch 515/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0229\n",
      "Epoch 516/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0098 - val_loss: 0.0207\n",
      "Epoch 517/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0236\n",
      "Epoch 518/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0182\n",
      "Epoch 519/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0096 - val_loss: 0.0199\n",
      "Epoch 520/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0103 - val_loss: 0.0199\n",
      "Epoch 521/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0208\n",
      "Epoch 522/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0235\n",
      "Epoch 523/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0096 - val_loss: 0.0187\n",
      "Epoch 524/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0185\n",
      "Epoch 525/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 0.0096 - val_loss: 0.0223\n",
      "Epoch 526/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0088 - val_loss: 0.0170\n",
      "Epoch 527/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0200\n",
      "Epoch 528/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0085 - val_loss: 0.0247\n",
      "Epoch 529/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0099 - val_loss: 0.0195\n",
      "Epoch 530/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0233\n",
      "Epoch 531/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0088 - val_loss: 0.0204\n",
      "Epoch 532/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0097 - val_loss: 0.0207\n",
      "Epoch 533/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0086 - val_loss: 0.0214\n",
      "Epoch 534/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0194\n",
      "Epoch 535/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0204\n",
      "Epoch 536/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0096 - val_loss: 0.0239\n",
      "Epoch 537/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0203\n",
      "Epoch 538/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0089 - val_loss: 0.0214\n",
      "Epoch 539/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0216\n",
      "Epoch 540/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0103 - val_loss: 0.0209\n",
      "Epoch 541/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0089 - val_loss: 0.0229\n",
      "Epoch 542/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0088 - val_loss: 0.0219\n",
      "Epoch 543/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0215\n",
      "Epoch 544/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0197\n",
      "Epoch 545/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0219\n",
      "Epoch 546/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0242\n",
      "Epoch 547/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0088 - val_loss: 0.0189\n",
      "Epoch 548/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0194\n",
      "Epoch 549/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0222\n",
      "Epoch 550/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0190\n",
      "Epoch 551/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0221\n",
      "Epoch 552/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0219\n",
      "Epoch 553/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0088 - val_loss: 0.0206\n",
      "Epoch 554/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0204\n",
      "Epoch 555/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0239\n",
      "Epoch 556/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0229\n",
      "Epoch 557/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0179\n",
      "Epoch 558/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0105 - val_loss: 0.0227\n",
      "Epoch 559/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0242\n",
      "Epoch 560/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0097 - val_loss: 0.0168\n",
      "Epoch 561/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0108 - val_loss: 0.0220\n",
      "Epoch 562/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0085 - val_loss: 0.0248\n",
      "Epoch 563/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0099 - val_loss: 0.0203\n",
      "Epoch 564/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0098 - val_loss: 0.0207\n",
      "Epoch 565/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0160\n",
      "Epoch 566/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0252\n",
      "Epoch 567/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0097 - val_loss: 0.0288\n",
      "Epoch 568/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0097 - val_loss: 0.0213\n",
      "Epoch 569/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0195\n",
      "Epoch 570/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0102 - val_loss: 0.0209\n",
      "Epoch 571/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0103 - val_loss: 0.0207\n",
      "Epoch 572/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0097 - val_loss: 0.0245\n",
      "Epoch 573/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0097 - val_loss: 0.0213\n",
      "Epoch 574/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0109 - val_loss: 0.0159\n",
      "Epoch 575/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0108 - val_loss: 0.0253\n",
      "Epoch 576/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0100 - val_loss: 0.0246\n",
      "Epoch 577/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0208\n",
      "Epoch 578/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0169\n",
      "Epoch 579/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0229\n",
      "Epoch 580/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0119 - val_loss: 0.0233\n",
      "Epoch 581/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0107 - val_loss: 0.0220\n",
      "Epoch 582/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0223\n",
      "Epoch 583/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0222\n",
      "Epoch 584/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0107 - val_loss: 0.0216\n",
      "Epoch 585/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0096 - val_loss: 0.0182\n",
      "Epoch 586/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0089 - val_loss: 0.0241\n",
      "Epoch 587/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0099 - val_loss: 0.0219\n",
      "Epoch 588/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0219\n",
      "Epoch 589/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0101 - val_loss: 0.0244\n",
      "Epoch 590/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0096 - val_loss: 0.0179\n",
      "Epoch 591/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0089 - val_loss: 0.0212\n",
      "Epoch 592/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0097 - val_loss: 0.0224\n",
      "Epoch 593/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0097 - val_loss: 0.0206\n",
      "Epoch 594/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0240\n",
      "Epoch 595/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0222\n",
      "Epoch 596/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0088 - val_loss: 0.0170\n",
      "Epoch 597/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0103 - val_loss: 0.0186\n",
      "Epoch 598/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0100 - val_loss: 0.0285\n",
      "Epoch 599/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0102 - val_loss: 0.0182\n",
      "Epoch 600/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0116 - val_loss: 0.0235\n",
      "Epoch 601/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0111 - val_loss: 0.0337\n",
      "Epoch 602/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0153\n",
      "Epoch 603/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0120 - val_loss: 0.0182\n",
      "Epoch 604/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.010 - 0s - loss: 0.0101 - val_loss: 0.0330\n",
      "Epoch 605/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0121 - val_loss: 0.0240\n",
      "Epoch 606/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0100 - val_loss: 0.0173\n",
      "Epoch 607/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0119 - val_loss: 0.0248\n",
      "Epoch 608/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0105 - val_loss: 0.0207\n",
      "Epoch 609/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0122 - val_loss: 0.0182\n",
      "Epoch 610/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0105 - val_loss: 0.0286\n",
      "Epoch 611/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0100 - val_loss: 0.0203\n",
      "Epoch 612/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0114 - val_loss: 0.0169\n",
      "Epoch 613/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0254\n",
      "Epoch 614/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0103 - val_loss: 0.0180\n",
      "Epoch 615/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0238\n",
      "Epoch 616/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0255\n",
      "Epoch 617/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0218\n",
      "Epoch 618/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0213\n",
      "Epoch 619/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0097 - val_loss: 0.0197\n",
      "Epoch 620/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0099 - val_loss: 0.0205\n",
      "Epoch 621/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0232\n",
      "Epoch 622/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0252\n",
      "Epoch 623/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0102 - val_loss: 0.0175\n",
      "Epoch 624/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0096 - val_loss: 0.0212\n",
      "Epoch 625/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0244\n",
      "Epoch 626/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0241\n",
      "Epoch 627/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0191\n",
      "Epoch 628/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0220\n",
      "Epoch 629/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0232\n",
      "Epoch 630/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0098 - val_loss: 0.0230\n",
      "Epoch 631/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0089 - val_loss: 0.0236\n",
      "Epoch 632/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0176\n",
      "Epoch 633/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0221\n",
      "Epoch 634/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0265\n",
      "Epoch 635/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0089 - val_loss: 0.0206\n",
      "Epoch 636/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0165\n",
      "Epoch 637/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0089 - val_loss: 0.0220\n",
      "Epoch 638/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0088 - val_loss: 0.0247\n",
      "Epoch 639/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0096 - val_loss: 0.0225\n",
      "Epoch 640/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0245\n",
      "Epoch 641/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0201\n",
      "Epoch 642/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0097 - val_loss: 0.0189\n",
      "Epoch 643/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0286\n",
      "Epoch 644/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0088 - val_loss: 0.0231\n",
      "Epoch 645/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0098 - val_loss: 0.0227\n",
      "Epoch 646/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0100 - val_loss: 0.0238\n",
      "Epoch 647/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0187\n",
      "Epoch 648/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0088 - val_loss: 0.0245\n",
      "Epoch 649/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0237\n",
      "Epoch 650/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0215\n",
      "Epoch 651/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0199\n",
      "Epoch 652/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0088 - val_loss: 0.0241\n",
      "Epoch 653/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0229\n",
      "Epoch 654/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0089 - val_loss: 0.0192\n",
      "Epoch 655/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0221\n",
      "Epoch 656/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0232\n",
      "Epoch 657/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0100 - val_loss: 0.0232\n",
      "Epoch 658/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0217\n",
      "Epoch 659/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0226\n",
      "Epoch 660/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0239\n",
      "Epoch 661/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0260\n",
      "Epoch 662/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0227\n",
      "Epoch 663/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0100 - val_loss: 0.0230\n",
      "Epoch 664/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0210\n",
      "Epoch 665/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0212\n",
      "Epoch 666/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0244\n",
      "Epoch 667/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0089 - val_loss: 0.0200\n",
      "Epoch 668/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0082 - val_loss: 0.0218\n",
      "Epoch 669/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0224\n",
      "Epoch 670/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0088 - val_loss: 0.0227\n",
      "Epoch 671/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0240\n",
      "Epoch 672/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0191\n",
      "Epoch 673/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0089 - val_loss: 0.0234\n",
      "Epoch 674/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0088 - val_loss: 0.0240\n",
      "Epoch 675/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0083 - val_loss: 0.0226\n",
      "Epoch 676/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0208\n",
      "Epoch 677/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0105 - val_loss: 0.0245\n",
      "Epoch 678/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0101 - val_loss: 0.0205\n",
      "Epoch 679/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0100 - val_loss: 0.0215\n",
      "Epoch 680/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0115 - val_loss: 0.0285\n",
      "Epoch 681/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0219\n",
      "Epoch 682/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0113 - val_loss: 0.0224\n",
      "Epoch 683/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0259\n",
      "Epoch 684/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0240\n",
      "Epoch 685/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0105 - val_loss: 0.0245\n",
      "Epoch 686/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0086 - val_loss: 0.0272\n",
      "Epoch 687/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0173\n",
      "Epoch 688/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0098 - val_loss: 0.0247\n",
      "Epoch 689/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0086 - val_loss: 0.0263\n",
      "Epoch 690/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0088 - val_loss: 0.0220\n",
      "Epoch 691/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0119 - val_loss: 0.0205\n",
      "Epoch 692/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0107 - val_loss: 0.0260\n",
      "Epoch 693/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0096 - val_loss: 0.0251\n",
      "Epoch 694/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0125 - val_loss: 0.0237\n",
      "Epoch 695/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0117 - val_loss: 0.0293\n",
      "Epoch 696/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0119 - val_loss: 0.0191\n",
      "Epoch 697/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0113 - val_loss: 0.0212\n",
      "Epoch 698/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0254\n",
      "Epoch 699/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0209\n",
      "Epoch 700/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0099 - val_loss: 0.0235\n",
      "Epoch 701/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0218\n",
      "Epoch 702/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0088 - val_loss: 0.0206\n",
      "Epoch 703/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0088 - val_loss: 0.0219\n",
      "Epoch 704/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0223\n",
      "Epoch 705/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0084 - val_loss: 0.0240\n",
      "Epoch 706/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0205\n",
      "Epoch 707/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0088 - val_loss: 0.0241\n",
      "Epoch 708/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0083 - val_loss: 0.0262\n",
      "Epoch 709/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0237\n",
      "Epoch 710/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0086 - val_loss: 0.0231\n",
      "Epoch 711/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0085 - val_loss: 0.0197\n",
      "Epoch 712/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0227\n",
      "Epoch 713/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0086 - val_loss: 0.0243\n",
      "Epoch 714/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0089 - val_loss: 0.0221\n",
      "Epoch 715/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0084 - val_loss: 0.0196\n",
      "Epoch 716/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0257\n",
      "Epoch 717/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0086 - val_loss: 0.0238\n",
      "Epoch 718/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0082 - val_loss: 0.0231\n",
      "Epoch 719/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0085 - val_loss: 0.0225\n",
      "Epoch 720/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0220\n",
      "Epoch 721/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0221\n",
      "Epoch 722/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0260\n",
      "Epoch 723/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0228\n",
      "Epoch 724/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0089 - val_loss: 0.0219\n",
      "Epoch 725/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0251\n",
      "Epoch 726/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0084 - val_loss: 0.0223\n",
      "Epoch 727/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0086 - val_loss: 0.0224\n",
      "Epoch 728/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0232\n",
      "Epoch 729/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0100 - val_loss: 0.0230\n",
      "Epoch 730/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0085 - val_loss: 0.0259\n",
      "Epoch 731/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0240\n",
      "Epoch 732/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0218\n",
      "Epoch 733/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0099 - val_loss: 0.0272\n",
      "Epoch 734/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0245\n",
      "Epoch 735/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0098 - val_loss: 0.0247\n",
      "Epoch 736/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0097 - val_loss: 0.0244\n",
      "Epoch 737/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0218\n",
      "Epoch 738/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0214\n",
      "Epoch 739/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0096 - val_loss: 0.0235\n",
      "Epoch 740/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0256\n",
      "Epoch 741/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0204\n",
      "Epoch 742/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0088 - val_loss: 0.0272\n",
      "Epoch 743/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0271\n",
      "Epoch 744/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0085 - val_loss: 0.0228\n",
      "Epoch 745/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0084 - val_loss: 0.0234\n",
      "Epoch 746/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0083 - val_loss: 0.0226\n",
      "Epoch 747/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0257\n",
      "Epoch 748/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0235\n",
      "Epoch 749/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0193\n",
      "Epoch 750/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0098 - val_loss: 0.0232\n",
      "Epoch 751/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0231\n",
      "Epoch 752/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0223\n",
      "Epoch 753/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0262\n",
      "Epoch 754/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0248\n",
      "Epoch 755/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0203\n",
      "Epoch 756/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0108 - val_loss: 0.0253\n",
      "Epoch 757/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0115 - val_loss: 0.0274\n",
      "Epoch 758/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0098 - val_loss: 0.0214\n",
      "Epoch 759/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0257\n",
      "Epoch 760/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0107 - val_loss: 0.0217\n",
      "Epoch 761/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0201\n",
      "Epoch 762/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0098 - val_loss: 0.0240\n",
      "Epoch 763/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0105 - val_loss: 0.0277\n",
      "Epoch 764/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0204\n",
      "Epoch 765/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0243\n",
      "Epoch 766/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0281\n",
      "Epoch 767/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0219\n",
      "Epoch 768/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0089 - val_loss: 0.0207\n",
      "Epoch 769/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0082 - val_loss: 0.0246\n",
      "Epoch 770/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0213\n",
      "Epoch 771/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0084 - val_loss: 0.0229\n",
      "Epoch 772/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0220\n",
      "Epoch 773/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0085 - val_loss: 0.0252\n",
      "Epoch 774/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0086 - val_loss: 0.0215\n",
      "Epoch 775/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0192\n",
      "Epoch 776/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0256\n",
      "Epoch 777/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0085 - val_loss: 0.0247\n",
      "Epoch 778/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0084 - val_loss: 0.0228\n",
      "Epoch 779/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0256\n",
      "Epoch 780/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0220\n",
      "Epoch 781/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0089 - val_loss: 0.0225\n",
      "Epoch 782/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0096 - val_loss: 0.0242\n",
      "Epoch 783/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0097 - val_loss: 0.0220\n",
      "Epoch 784/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0244\n",
      "Epoch 785/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0101 - val_loss: 0.0214\n",
      "Epoch 786/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0100 - val_loss: 0.0265\n",
      "Epoch 787/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0109 - val_loss: 0.0261\n",
      "Epoch 788/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0086 - val_loss: 0.0237\n",
      "Epoch 789/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 0.0103 - val_loss: 0.0272\n",
      "Epoch 790/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0113 - val_loss: 0.0280\n",
      "Epoch 791/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0211\n",
      "Epoch 792/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0110 - val_loss: 0.0242\n",
      "Epoch 793/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0248\n",
      "Epoch 794/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0215\n",
      "Epoch 795/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0253\n",
      "Epoch 796/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0223\n",
      "Epoch 797/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0219\n",
      "Epoch 798/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0266\n",
      "Epoch 799/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0225\n",
      "Epoch 800/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0228\n",
      "Epoch 801/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0080 - val_loss: 0.0287\n",
      "Epoch 802/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0222\n",
      "Epoch 803/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0198\n",
      "Epoch 804/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0285\n",
      "Epoch 805/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0257\n",
      "Epoch 806/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0088 - val_loss: 0.0208\n",
      "Epoch 807/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0083 - val_loss: 0.0258\n",
      "Epoch 808/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0089 - val_loss: 0.0276\n",
      "Epoch 809/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0083 - val_loss: 0.0214\n",
      "Epoch 810/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0227\n",
      "Epoch 811/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0083 - val_loss: 0.0244\n",
      "Epoch 812/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0086 - val_loss: 0.0248\n",
      "Epoch 813/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0084 - val_loss: 0.0252\n",
      "Epoch 814/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0081 - val_loss: 0.0220\n",
      "Epoch 815/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0089 - val_loss: 0.0230\n",
      "Epoch 816/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0255\n",
      "Epoch 817/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0241\n",
      "Epoch 818/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0096 - val_loss: 0.0232\n",
      "Epoch 819/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0085 - val_loss: 0.0260\n",
      "Epoch 820/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0102 - val_loss: 0.0250\n",
      "Epoch 821/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0203\n",
      "Epoch 822/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0085 - val_loss: 0.0282\n",
      "Epoch 823/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0101 - val_loss: 0.0269\n",
      "Epoch 824/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0098 - val_loss: 0.0178\n",
      "Epoch 825/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0097 - val_loss: 0.0223\n",
      "Epoch 826/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0097 - val_loss: 0.0263\n",
      "Epoch 827/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0100 - val_loss: 0.0206\n",
      "Epoch 828/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0110 - val_loss: 0.0255\n",
      "Epoch 829/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0101 - val_loss: 0.0271\n",
      "Epoch 830/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0209\n",
      "Epoch 831/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0115 - val_loss: 0.0226\n",
      "Epoch 832/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0101 - val_loss: 0.0294\n",
      "Epoch 833/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0115 - val_loss: 0.0235\n",
      "Epoch 834/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0102 - val_loss: 0.0218\n",
      "Epoch 835/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0115 - val_loss: 0.0240\n",
      "Epoch 836/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0113 - val_loss: 0.0285\n",
      "Epoch 837/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0097 - val_loss: 0.0212\n",
      "Epoch 838/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0221\n",
      "Epoch 839/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0240\n",
      "Epoch 840/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0227\n",
      "Epoch 841/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0216\n",
      "Epoch 842/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0089 - val_loss: 0.0238\n",
      "Epoch 843/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0086 - val_loss: 0.0267\n",
      "Epoch 844/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0086 - val_loss: 0.0239\n",
      "Epoch 845/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0234\n",
      "Epoch 846/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0085 - val_loss: 0.0271\n",
      "Epoch 847/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0088 - val_loss: 0.0233\n",
      "Epoch 848/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0213\n",
      "Epoch 849/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0246\n",
      "Epoch 850/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0210\n",
      "Epoch 851/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0239\n",
      "Epoch 852/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0229\n",
      "Epoch 853/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0084 - val_loss: 0.0242\n",
      "Epoch 854/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0220\n",
      "Epoch 855/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0098 - val_loss: 0.0231\n",
      "Epoch 856/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0099 - val_loss: 0.0249\n",
      "Epoch 857/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0077 - val_loss: 0.0255\n",
      "Epoch 858/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0242\n",
      "Epoch 859/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0255\n",
      "Epoch 860/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0085 - val_loss: 0.0258\n",
      "Epoch 861/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0244\n",
      "Epoch 862/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0254\n",
      "Epoch 863/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0229\n",
      "Epoch 864/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0084 - val_loss: 0.0285\n",
      "Epoch 865/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0255\n",
      "Epoch 866/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0101 - val_loss: 0.0235\n",
      "Epoch 867/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0084 - val_loss: 0.0232\n",
      "Epoch 868/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0097 - val_loss: 0.0265\n",
      "Epoch 869/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0089 - val_loss: 0.0269\n",
      "Epoch 870/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0086 - val_loss: 0.0196\n",
      "Epoch 871/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0204\n",
      "Epoch 872/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0083 - val_loss: 0.0284\n",
      "Epoch 873/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0238\n",
      "Epoch 874/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0083 - val_loss: 0.0246\n",
      "Epoch 875/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0210\n",
      "Epoch 876/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0082 - val_loss: 0.0229\n",
      "Epoch 877/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0238\n",
      "Epoch 878/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0086 - val_loss: 0.0282\n",
      "Epoch 879/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0096 - val_loss: 0.0235\n",
      "Epoch 880/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0102 - val_loss: 0.0246\n",
      "Epoch 881/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0279\n",
      "Epoch 882/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0206\n",
      "Epoch 883/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0108 - val_loss: 0.0258\n",
      "Epoch 884/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0284\n",
      "Epoch 885/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0213\n",
      "Epoch 886/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0085 - val_loss: 0.0231\n",
      "Epoch 887/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0080 - val_loss: 0.0254\n",
      "Epoch 888/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0231\n",
      "Epoch 889/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0228\n",
      "Epoch 890/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0083 - val_loss: 0.0275\n",
      "Epoch 891/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0089 - val_loss: 0.0258\n",
      "Epoch 892/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0084 - val_loss: 0.0238\n",
      "Epoch 893/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0084 - val_loss: 0.0258\n",
      "Epoch 894/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0086 - val_loss: 0.0256\n",
      "Epoch 895/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0088 - val_loss: 0.0194\n",
      "Epoch 896/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0234\n",
      "Epoch 897/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0252\n",
      "Epoch 898/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0097 - val_loss: 0.0230\n",
      "Epoch 899/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0100 - val_loss: 0.0231\n",
      "Epoch 900/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0096 - val_loss: 0.0273\n",
      "Epoch 901/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0082 - val_loss: 0.0236\n",
      "Epoch 902/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0097 - val_loss: 0.0231\n",
      "Epoch 903/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0100 - val_loss: 0.0269\n",
      "Epoch 904/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0081 - val_loss: 0.0232\n",
      "Epoch 905/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0247\n",
      "Epoch 906/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0277\n",
      "Epoch 907/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0089 - val_loss: 0.0232\n",
      "Epoch 908/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0096 - val_loss: 0.0231\n",
      "Epoch 909/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0081 - val_loss: 0.0265\n",
      "Epoch 910/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0084 - val_loss: 0.0222\n",
      "Epoch 911/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0084 - val_loss: 0.0229\n",
      "Epoch 912/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0082 - val_loss: 0.0241\n",
      "Epoch 913/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0086 - val_loss: 0.0255\n",
      "Epoch 914/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0227\n",
      "Epoch 915/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0085 - val_loss: 0.0247\n",
      "Epoch 916/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0081 - val_loss: 0.0256\n",
      "Epoch 917/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0081 - val_loss: 0.0237\n",
      "Epoch 918/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0082 - val_loss: 0.0237\n",
      "Epoch 919/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0084 - val_loss: 0.0268\n",
      "Epoch 920/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0081 - val_loss: 0.0234\n",
      "Epoch 921/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0231\n",
      "Epoch 922/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0081 - val_loss: 0.0257\n",
      "Epoch 923/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0085 - val_loss: 0.0233\n",
      "Epoch 924/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0079 - val_loss: 0.0234\n",
      "Epoch 925/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0085 - val_loss: 0.0244\n",
      "Epoch 926/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0084 - val_loss: 0.0262\n",
      "Epoch 927/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0234\n",
      "Epoch 928/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0088 - val_loss: 0.0196\n",
      "Epoch 929/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0253\n",
      "Epoch 930/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0282\n",
      "Epoch 931/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0085 - val_loss: 0.0193\n",
      "Epoch 932/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0088 - val_loss: 0.0239\n",
      "Epoch 933/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0292\n",
      "Epoch 934/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0083 - val_loss: 0.0225\n",
      "Epoch 935/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0207\n",
      "Epoch 936/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0084 - val_loss: 0.0270\n",
      "Epoch 937/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0244\n",
      "Epoch 938/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0104 - val_loss: 0.0196\n",
      "Epoch 939/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0102 - val_loss: 0.0289\n",
      "Epoch 940/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0118 - val_loss: 0.0264\n",
      "Epoch 941/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0103 - val_loss: 0.0199\n",
      "Epoch 942/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0269\n",
      "Epoch 943/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0255\n",
      "Epoch 944/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0095 - val_loss: 0.0212\n",
      "Epoch 945/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0235\n",
      "Epoch 946/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0263\n",
      "Epoch 947/1000\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.007 - 0s - loss: 0.0084 - val_loss: 0.0246\n",
      "Epoch 948/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0223\n",
      "Epoch 949/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0274\n",
      "Epoch 950/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0099 - val_loss: 0.0260\n",
      "Epoch 951/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0226\n",
      "Epoch 952/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0235\n",
      "Epoch 953/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0120 - val_loss: 0.0270\n",
      "Epoch 954/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0293\n",
      "Epoch 955/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0115 - val_loss: 0.0281\n",
      "Epoch 956/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0123 - val_loss: 0.0221\n",
      "Epoch 957/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0098 - val_loss: 0.0192\n",
      "Epoch 958/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0099 - val_loss: 0.0238\n",
      "Epoch 959/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0106 - val_loss: 0.0259\n",
      "Epoch 960/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0091 - val_loss: 0.0213\n",
      "Epoch 961/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0101 - val_loss: 0.0247\n",
      "Epoch 962/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0105 - val_loss: 0.0245\n",
      "Epoch 963/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0090 - val_loss: 0.0219\n",
      "Epoch 964/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0098 - val_loss: 0.0263\n",
      "Epoch 965/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s - loss: 0.0089 - val_loss: 0.0253\n",
      "Epoch 966/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0086 - val_loss: 0.0213\n",
      "Epoch 967/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0086 - val_loss: 0.0258\n",
      "Epoch 968/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0082 - val_loss: 0.0276\n",
      "Epoch 969/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0086 - val_loss: 0.0242\n",
      "Epoch 970/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0088 - val_loss: 0.0241\n",
      "Epoch 971/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0082 - val_loss: 0.0285\n",
      "Epoch 972/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0255\n",
      "Epoch 973/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0080 - val_loss: 0.0247\n",
      "Epoch 974/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0084 - val_loss: 0.0260\n",
      "Epoch 975/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0084 - val_loss: 0.0241\n",
      "Epoch 976/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0086 - val_loss: 0.0269\n",
      "Epoch 977/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0080 - val_loss: 0.0242\n",
      "Epoch 978/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0088 - val_loss: 0.0253\n",
      "Epoch 979/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0085 - val_loss: 0.0268\n",
      "Epoch 980/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0253\n",
      "Epoch 981/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0236\n",
      "Epoch 982/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0089 - val_loss: 0.0229\n",
      "Epoch 983/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0082 - val_loss: 0.0225\n",
      "Epoch 984/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0083 - val_loss: 0.0245\n",
      "Epoch 985/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0082 - val_loss: 0.0237\n",
      "Epoch 986/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0086 - val_loss: 0.0247\n",
      "Epoch 987/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0079 - val_loss: 0.0252\n",
      "Epoch 988/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0085 - val_loss: 0.0248\n",
      "Epoch 989/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0086 - val_loss: 0.0254\n",
      "Epoch 990/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0093 - val_loss: 0.0240\n",
      "Epoch 991/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0087 - val_loss: 0.0246\n",
      "Epoch 992/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0094 - val_loss: 0.0250\n",
      "Epoch 993/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0080 - val_loss: 0.0229\n",
      "Epoch 994/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0092 - val_loss: 0.0259\n",
      "Epoch 995/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0086 - val_loss: 0.0237\n",
      "Epoch 996/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0089 - val_loss: 0.0214\n",
      "Epoch 997/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0083 - val_loss: 0.0257\n",
      "Epoch 998/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0080 - val_loss: 0.0245\n",
      "Epoch 999/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0081 - val_loss: 0.0246\n",
      "Epoch 1000/1000\n",
      "90/90 [==============================] - 0s - loss: 0.0079 - val_loss: 0.0250\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEKCAYAAADuEgmxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkoYxxhi/WdIwxhjjt/8HQ7pQ7ntr+KUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0e8dae20d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(280, input_shape=(1,), activation='relu'))\n",
    "model.add(Dense(180, activation='relu'))\n",
    "model.add(Dense(80, activation='relu'))\n",
    "model.add(Dense(80, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "sine = sine_function(noiserate=0.2)\n",
    "X,y = trainingData(sine)\n",
    "X_test, y_test = testData(sine)\n",
    "model.fit(X, y, epochs=1000,validation_split=0.1)\n",
    "testModel(X,y,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelimiz bu kez de elindeki çok miktarda parametreyi kullanarak, training set'teki her bir örneğe yaklaşabildiği kadar yaklaşmaya çalıştı. Modelin training loss'u çok küçük olsa da, daha önce görmediğı örneklerde ideal büyüklükte bir ağ'dan daha kötü performans sergiler.\n",
    "\n",
    "Loss'ları inceleyince de, validation loss'un 100. epoch civarında düşmeyi bıraktığını, training loss'un ise bir süre daha düşmeye devam ettiğini görüyoruz. İşte tam da bu noktada ağımız overfit etmeye başlamış demek ki. İleride overfit olayını engellemek için çeşitli yöntemlerden bahsedeceğim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Özet\n",
    "\n",
    "- Validation set olmadan ağın elimizdeki veriyi ne kadar iyi genelleştirdiğini anlamak imkansızdır. Training loss çok düşük olsa da, ağ bizim verdiğimiz örnekleri ezberlemiş (overfit) olabilir.\n",
    "- Ağ'ın veriyi öğrenmek için yeterli karmaşıklığa sahip olmaması, yeterince ögrenememesine (underfit) yol açar. Bu durum hem training hem de validation loss'un yüksek olmasından anlaşılabilir. \n",
    "- Ağ'in veriyi ögrenmek için gerekenden fazla karmaşıklığa sahip olmasi, veriyi ezberlemesine (overfit) yol açar. Bu durum training loss düşerken, validation loss'un düşmeye devam etmemesi veya yükselmesiyle anlaşılabilir.\n",
    "\n",
    "## Ödevler\n",
    "\n",
    "- Veriyi öğrenmek için ideal olan modeli bulun.\n",
    "- Training set'teki veri miktarını arttırmak, overfit durumunu nasıl etkiliyor?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
